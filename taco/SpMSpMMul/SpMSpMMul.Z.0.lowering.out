// -----// IR Dump After LinalgGeneralization (linalg-generalize-named-ops) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, %arg1: tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
  %0 = bufferization.alloc_tensor() : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) outs(%0 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.mulf %in, %in_0 : f32
    %3 = arith.addf %out, %2 : f32
    linalg.yield %3 : f32
  } -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  return %1 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
}

// -----// IR Dump After PreSparsificationRewrite (pre-sparsification-rewrite) //----- //
#map = affine_map<(d0, d1, d2) -> (d0, d2)>
#map1 = affine_map<(d0, d1, d2) -> (d2, d1)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, %arg1: tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %0 = bufferization.alloc_tensor() : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) outs(%0 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.mulf %in, %in_0 : f32
      %3 = arith.addf %out, %2 : f32
      linalg.yield %3 : f32
    } -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %1 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, %arg1: tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
  %0 = bufferization.alloc_tensor() : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) outs(%0 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.mulf %in, %in_0 : f32
    %3 = arith.addf %out, %2 : f32
    linalg.yield %3 : f32
  } -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  return %1 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
}

// -----// IR Dump After SparsificationPass (sparsification) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, %arg1: tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %c15 = arith.constant 15 : index
    %c16 = arith.constant 16 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = bufferization.alloc_tensor() {bufferization.escape = [true]} : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>> to memref<?xindex>
    %2 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>> to memref<?xindex>
    %3 = sparse_tensor.values %arg0 : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>> to memref<?xf32>
    %4 = sparse_tensor.positions %arg1 {level = 1 : index} : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>> to memref<?xindex>
    %5 = sparse_tensor.coordinates %arg1 {level = 1 : index} : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>> to memref<?xindex>
    %6 = sparse_tensor.values %arg1 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>> to memref<?xf32>
    %7 = sparse_tensor.values %0 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to memref<?xf32>
    scf.parallel (%arg2) = (%c0) to (%c15) step (%c1) {
      scf.parallel (%arg3) = (%c0) to (%c16) step (%c1) {
        %9 = arith.muli %arg2, %c16 : index
        %10 = arith.addi %9, %arg3 : index
        %11 = memref.load %7[%10] : memref<?xf32>
        %12 = memref.load %1[%arg2] : memref<?xindex>
        %13 = arith.addi %arg2, %c1 : index
        %14 = memref.load %1[%13] : memref<?xindex>
        %15 = memref.load %4[%arg3] : memref<?xindex>
        %16 = arith.addi %arg3, %c1 : index
        %17 = memref.load %4[%16] : memref<?xindex>
        %18:3 = scf.while (%arg4 = %12, %arg5 = %15, %arg6 = %11) : (index, index, f32) -> (index, index, f32) {
          %19 = arith.cmpi ult, %arg4, %14 : index
          %20 = arith.cmpi ult, %arg5, %17 : index
          %21 = arith.andi %19, %20 : i1
          scf.condition(%21) %arg4, %arg5, %arg6 : index, index, f32
        } do {
        ^bb0(%arg4: index, %arg5: index, %arg6: f32):
          %19 = memref.load %2[%arg4] : memref<?xindex>
          %20 = memref.load %5[%arg5] : memref<?xindex>
          %21 = arith.cmpi ult, %20, %19 : index
          %22 = arith.select %21, %20, %19 : index
          %23 = arith.cmpi eq, %19, %22 : index
          %24 = arith.cmpi eq, %20, %22 : index
          %25 = arith.andi %23, %24 : i1
          %26 = scf.if %25 -> (f32) {
            %33 = memref.load %3[%arg4] : memref<?xf32>
            %34 = memref.load %6[%arg5] : memref<?xf32>
            %35 = arith.mulf %33, %34 : f32
            %36 = arith.addf %arg6, %35 : f32
            scf.yield %36 : f32
          } else {
            scf.yield %arg6 : f32
          }
          %27 = arith.cmpi eq, %19, %22 : index
          %28 = arith.addi %arg4, %c1 : index
          %29 = arith.select %27, %28, %arg4 : index
          %30 = arith.cmpi eq, %20, %22 : index
          %31 = arith.addi %arg5, %c1 : index
          %32 = arith.select %30, %31, %arg5 : index
          scf.yield %29, %32, %26 : index, index, f32
        } attributes {"Emitted from" = "linalg.generic"}
        memref.store %18#2, %7[%10] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %8 = sparse_tensor.load %0 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %8 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After PostSparsificationRewrite (post-sparsification-rewrite) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, %arg1: tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>>) -> tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %c15 = arith.constant 15 : index
    %c16 = arith.constant 16 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = bufferization.alloc_tensor() {bufferization.escape = [true]} : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>> to memref<?xindex>
    %2 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>> to memref<?xindex>
    %3 = sparse_tensor.values %arg0 : tensor<15x15xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>> to memref<?xf32>
    %4 = sparse_tensor.positions %arg1 {level = 1 : index} : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>> to memref<?xindex>
    %5 = sparse_tensor.coordinates %arg1 {level = 1 : index} : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>> to memref<?xindex>
    %6 = sparse_tensor.values %arg1 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ], dimToLvl = affine_map<(d0, d1) -> (d1, d0)> }>> to memref<?xf32>
    %7 = sparse_tensor.values %0 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to memref<?xf32>
    scf.parallel (%arg2) = (%c0) to (%c15) step (%c1) {
      scf.parallel (%arg3) = (%c0) to (%c16) step (%c1) {
        %9 = arith.muli %arg2, %c16 : index
        %10 = arith.addi %9, %arg3 : index
        %11 = memref.load %7[%10] : memref<?xf32>
        %12 = memref.load %1[%arg2] : memref<?xindex>
        %13 = arith.addi %arg2, %c1 : index
        %14 = memref.load %1[%13] : memref<?xindex>
        %15 = memref.load %4[%arg3] : memref<?xindex>
        %16 = arith.addi %arg3, %c1 : index
        %17 = memref.load %4[%16] : memref<?xindex>
        %18:3 = scf.while (%arg4 = %12, %arg5 = %15, %arg6 = %11) : (index, index, f32) -> (index, index, f32) {
          %19 = arith.cmpi ult, %arg4, %14 : index
          %20 = arith.cmpi ult, %arg5, %17 : index
          %21 = arith.andi %19, %20 : i1
          scf.condition(%21) %arg4, %arg5, %arg6 : index, index, f32
        } do {
        ^bb0(%arg4: index, %arg5: index, %arg6: f32):
          %19 = memref.load %2[%arg4] : memref<?xindex>
          %20 = memref.load %5[%arg5] : memref<?xindex>
          %21 = arith.cmpi ult, %20, %19 : index
          %22 = arith.select %21, %20, %19 : index
          %23 = arith.cmpi eq, %19, %22 : index
          %24 = arith.cmpi eq, %20, %22 : index
          %25 = arith.andi %23, %24 : i1
          %26 = scf.if %25 -> (f32) {
            %33 = memref.load %3[%arg4] : memref<?xf32>
            %34 = memref.load %6[%arg5] : memref<?xf32>
            %35 = arith.mulf %33, %34 : f32
            %36 = arith.addf %arg6, %35 : f32
            scf.yield %36 : f32
          } else {
            scf.yield %arg6 : f32
          }
          %27 = arith.cmpi eq, %19, %22 : index
          %28 = arith.addi %arg4, %c1 : index
          %29 = arith.select %27, %28, %arg4 : index
          %30 = arith.cmpi eq, %20, %22 : index
          %31 = arith.addi %arg5, %c1 : index
          %32 = arith.select %30, %31, %arg5 : index
          scf.yield %29, %32, %26 : index, index, f32
        } attributes {"Emitted from" = "linalg.generic"}
        memref.store %18#2, %7[%10] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %8 = sparse_tensor.load %0 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %8 : tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After SparseTensorCodegen (sparse-tensor-codegen) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>) -> (memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) attributes {llvm.emit_c_interface} {
    %c15 = arith.constant 15 : index
    %c16 = arith.constant 16 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c15_0 = arith.constant 15 : index
    %c16_1 = arith.constant 16 : index
    %0 = arith.muli %c15_0, %c16_1 : index
    %alloc = memref.alloc(%0) : memref<?xf32>
    %1 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %c0_2 = arith.constant 0 : index
    %2 = sparse_tensor.storage_specifier.set %1  lvl_sz at 0 with %c15_0 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %3 = sparse_tensor.storage_specifier.set %2  lvl_sz at 1 with %c16_1 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %c1_3 = arith.constant 1 : index
    %c15_4 = arith.constant 15 : index
    %4 = arith.muli %c1_3, %c15_4 : index
    %c16_5 = arith.constant 16 : index
    %5 = arith.muli %4, %c16_5 : index
    %cst = arith.constant 0.000000e+00 : f32
    %6 = sparse_tensor.storage_specifier.get %3  val_mem_sz : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %outBuffer, %newSize = sparse_tensor.push_back %6, %alloc, %cst, %5 : index, memref<?xf32>, f32, index
    %7 = sparse_tensor.storage_specifier.set %3  val_mem_sz with %newSize : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %8 = builtin.unrealized_conversion_cast %outBuffer, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    scf.parallel (%arg8) = (%c0) to (%c15) step (%c1) {
      scf.parallel (%arg9) = (%c0) to (%c16) step (%c1) {
        %10 = arith.muli %arg8, %c16 : index
        %11 = arith.addi %10, %arg9 : index
        %12 = memref.load %outBuffer[%11] : memref<?xf32>
        %13 = memref.load %arg0[%arg8] : memref<?xindex>
        %14 = arith.addi %arg8, %c1 : index
        %15 = memref.load %arg0[%14] : memref<?xindex>
        %16 = memref.load %arg4[%arg9] : memref<?xindex>
        %17 = arith.addi %arg9, %c1 : index
        %18 = memref.load %arg4[%17] : memref<?xindex>
        %19:3 = scf.while (%arg10 = %13, %arg11 = %16, %arg12 = %12) : (index, index, f32) -> (index, index, f32) {
          %20 = arith.cmpi ult, %arg10, %15 : index
          %21 = arith.cmpi ult, %arg11, %18 : index
          %22 = arith.andi %20, %21 : i1
          scf.condition(%22) %arg10, %arg11, %arg12 : index, index, f32
        } do {
        ^bb0(%arg10: index, %arg11: index, %arg12: f32):
          %20 = memref.load %arg1[%arg10] : memref<?xindex>
          %21 = memref.load %arg5[%arg11] : memref<?xindex>
          %22 = arith.cmpi ult, %21, %20 : index
          %23 = arith.select %22, %21, %20 : index
          %24 = arith.cmpi eq, %20, %23 : index
          %25 = arith.cmpi eq, %21, %23 : index
          %26 = arith.andi %24, %25 : i1
          %27 = scf.if %26 -> (f32) {
            %34 = memref.load %arg2[%arg10] : memref<?xf32>
            %35 = memref.load %arg6[%arg11] : memref<?xf32>
            %36 = arith.mulf %34, %35 : f32
            %37 = arith.addf %arg12, %36 : f32
            scf.yield %37 : f32
          } else {
            scf.yield %arg12 : f32
          }
          %28 = arith.cmpi eq, %20, %23 : index
          %29 = arith.addi %arg10, %c1 : index
          %30 = arith.select %28, %29, %arg10 : index
          %31 = arith.cmpi eq, %21, %23 : index
          %32 = arith.addi %arg11, %c1 : index
          %33 = arith.select %31, %32, %arg11 : index
          scf.yield %30, %33, %27 : index, index, f32
        } attributes {"Emitted from" = "linalg.generic"}
        memref.store %19#2, %outBuffer[%11] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %9 = builtin.unrealized_conversion_cast %outBuffer, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to tensor<15x16xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %outBuffer, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After SparseBufferRewrite (sparse-buffer-rewrite) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "compressed" ] }>>) -> (memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) attributes {llvm.emit_c_interface} {
    %c240 = arith.constant 240 : index
    %c15 = arith.constant 15 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c240) : memref<?xf32>
    %0 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = sparse_tensor.storage_specifier.set %0  lvl_sz at 0 with %c15 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %2 = sparse_tensor.storage_specifier.set %1  lvl_sz at 1 with %c16 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %3 = sparse_tensor.storage_specifier.get %2  val_mem_sz : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %4 = arith.addi %3, %c240 : index
    %5 = arith.cmpi ugt, %4, %c240 : index
    %6 = scf.if %5 -> (memref<?xf32>) {
      %8 = scf.while (%arg8 = %c240) : (index) -> index {
        %10 = arith.muli %arg8, %c2 : index
        %11 = arith.cmpi ugt, %4, %10 : index
        scf.condition(%11) %10 : index
      } do {
      ^bb0(%arg8: index):
        scf.yield %arg8 : index
      }
      %9 = memref.realloc %alloc(%8) : memref<?xf32> to memref<?xf32>
      scf.yield %9 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %6[%3] [%c240] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %7 = sparse_tensor.storage_specifier.set %2  val_mem_sz with %4 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    scf.parallel (%arg8) = (%c0) to (%c15) step (%c1) {
      scf.parallel (%arg9) = (%c0) to (%c16) step (%c1) {
        %8 = arith.muli %arg8, %c16 : index
        %9 = arith.addi %8, %arg9 : index
        %10 = memref.load %6[%9] : memref<?xf32>
        %11 = memref.load %arg0[%arg8] : memref<?xindex>
        %12 = arith.addi %arg8, %c1 : index
        %13 = memref.load %arg0[%12] : memref<?xindex>
        %14 = memref.load %arg4[%arg9] : memref<?xindex>
        %15 = arith.addi %arg9, %c1 : index
        %16 = memref.load %arg4[%15] : memref<?xindex>
        %17:3 = scf.while (%arg10 = %11, %arg11 = %14, %arg12 = %10) : (index, index, f32) -> (index, index, f32) {
          %18 = arith.cmpi ult, %arg10, %13 : index
          %19 = arith.cmpi ult, %arg11, %16 : index
          %20 = arith.andi %18, %19 : i1
          scf.condition(%20) %arg10, %arg11, %arg12 : index, index, f32
        } do {
        ^bb0(%arg10: index, %arg11: index, %arg12: f32):
          %18 = memref.load %arg1[%arg10] : memref<?xindex>
          %19 = memref.load %arg5[%arg11] : memref<?xindex>
          %20 = arith.cmpi ult, %19, %18 : index
          %21 = arith.select %20, %19, %18 : index
          %22 = arith.cmpi eq, %18, %21 : index
          %23 = arith.cmpi eq, %19, %21 : index
          %24 = arith.andi %22, %23 : i1
          %25 = scf.if %24 -> (f32) {
            %32 = memref.load %arg2[%arg10] : memref<?xf32>
            %33 = memref.load %arg6[%arg11] : memref<?xf32>
            %34 = arith.mulf %32, %33 : f32
            %35 = arith.addf %arg12, %34 : f32
            scf.yield %35 : f32
          } else {
            scf.yield %arg12 : f32
          }
          %26 = arith.cmpi eq, %18, %21 : index
          %27 = arith.addi %arg10, %c1 : index
          %28 = arith.select %26, %27, %arg10 : index
          %29 = arith.cmpi eq, %19, %21 : index
          %30 = arith.addi %arg11, %c1 : index
          %31 = arith.select %29, %30, %arg11 : index
          scf.yield %28, %31, %25 : index, index, f32
        } attributes {"Emitted from" = "linalg.generic"}
        memref.store %17#2, %6[%9] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %6, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After StorageSpecifierToLLVM (sparse-storage-specifier-to-llvm) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c240 = arith.constant 240 : index
    %c15 = arith.constant 15 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c240) : memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %c0_i64 = arith.constant 0 : i64
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = arith.index_cast %c15 : index to i64
    %3 = llvm.insertvalue %2, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %4 = arith.index_cast %c16 : index to i64
    %5 = llvm.insertvalue %4, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %6 = llvm.extractvalue %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %8 = arith.addi %7, %c240 : index
    %9 = arith.cmpi ugt, %8, %c240 : index
    %10 = scf.if %9 -> (memref<?xf32>) {
      %13 = scf.while (%arg8 = %c240) : (index) -> index {
        %15 = arith.muli %arg8, %c2 : index
        %16 = arith.cmpi ugt, %8, %15 : index
        scf.condition(%16) %15 : index
      } do {
      ^bb0(%arg8: index):
        scf.yield %arg8 : index
      }
      %14 = memref.realloc %alloc(%13) : memref<?xf32> to memref<?xf32>
      scf.yield %14 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %10[%7] [%c240] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %11 = arith.index_cast %8 : index to i64
    %12 = llvm.insertvalue %11, %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    scf.parallel (%arg8) = (%c0) to (%c15) step (%c1) {
      scf.parallel (%arg9) = (%c0) to (%c16) step (%c1) {
        %13 = arith.muli %arg8, %c16 : index
        %14 = arith.addi %13, %arg9 : index
        %15 = memref.load %10[%14] : memref<?xf32>
        %16 = memref.load %arg0[%arg8] : memref<?xindex>
        %17 = arith.addi %arg8, %c1 : index
        %18 = memref.load %arg0[%17] : memref<?xindex>
        %19 = memref.load %arg4[%arg9] : memref<?xindex>
        %20 = arith.addi %arg9, %c1 : index
        %21 = memref.load %arg4[%20] : memref<?xindex>
        %22:3 = scf.while (%arg10 = %16, %arg11 = %19, %arg12 = %15) : (index, index, f32) -> (index, index, f32) {
          %23 = arith.cmpi ult, %arg10, %18 : index
          %24 = arith.cmpi ult, %arg11, %21 : index
          %25 = arith.andi %23, %24 : i1
          scf.condition(%25) %arg10, %arg11, %arg12 : index, index, f32
        } do {
        ^bb0(%arg10: index, %arg11: index, %arg12: f32):
          %23 = memref.load %arg1[%arg10] : memref<?xindex>
          %24 = memref.load %arg5[%arg11] : memref<?xindex>
          %25 = arith.cmpi ult, %24, %23 : index
          %26 = arith.select %25, %24, %23 : index
          %27 = arith.cmpi eq, %23, %26 : index
          %28 = arith.cmpi eq, %24, %26 : index
          %29 = arith.andi %27, %28 : i1
          %30 = scf.if %29 -> (f32) {
            %37 = memref.load %arg2[%arg10] : memref<?xf32>
            %38 = memref.load %arg6[%arg11] : memref<?xf32>
            %39 = arith.mulf %37, %38 : f32
            %40 = arith.addf %arg12, %39 : f32
            scf.yield %40 : f32
          } else {
            scf.yield %arg12 : f32
          }
          %31 = arith.cmpi eq, %23, %26 : index
          %32 = arith.addi %arg10, %c1 : index
          %33 = arith.select %31, %32, %arg10 : index
          %34 = arith.cmpi eq, %24, %26 : index
          %35 = arith.addi %arg11, %c1 : index
          %36 = arith.select %34, %35, %arg11 : index
          scf.yield %33, %36, %30 : index, index, f32
        } attributes {"Emitted from" = "linalg.generic"}
        memref.store %22#2, %10[%14] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %10, %12 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After mlir::sparse_tensor::SparsificationAndBufferizationPass () //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c240 = arith.constant 240 : index
    %c15 = arith.constant 15 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c240) : memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %c0_i64 = arith.constant 0 : i64
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = arith.index_cast %c15 : index to i64
    %3 = llvm.insertvalue %2, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %4 = arith.index_cast %c16 : index to i64
    %5 = llvm.insertvalue %4, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %6 = llvm.extractvalue %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %8 = arith.addi %7, %c240 : index
    %9 = arith.cmpi ugt, %8, %c240 : index
    %10 = scf.if %9 -> (memref<?xf32>) {
      %13 = scf.while (%arg8 = %c240) : (index) -> index {
        %15 = arith.muli %arg8, %c2 : index
        %16 = arith.cmpi ugt, %8, %15 : index
        scf.condition(%16) %15 : index
      } do {
      ^bb0(%arg8: index):
        scf.yield %arg8 : index
      }
      %14 = memref.realloc %alloc(%13) : memref<?xf32> to memref<?xf32>
      scf.yield %14 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %10[%7] [%c240] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %11 = arith.index_cast %8 : index to i64
    %12 = llvm.insertvalue %11, %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    scf.parallel (%arg8) = (%c0) to (%c15) step (%c1) {
      scf.parallel (%arg9) = (%c0) to (%c16) step (%c1) {
        %13 = arith.muli %arg8, %c16 : index
        %14 = arith.addi %13, %arg9 : index
        %15 = memref.load %10[%14] : memref<?xf32>
        %16 = memref.load %arg0[%arg8] : memref<?xindex>
        %17 = arith.addi %arg8, %c1 : index
        %18 = memref.load %arg0[%17] : memref<?xindex>
        %19 = memref.load %arg4[%arg9] : memref<?xindex>
        %20 = arith.addi %arg9, %c1 : index
        %21 = memref.load %arg4[%20] : memref<?xindex>
        %22:3 = scf.while (%arg10 = %16, %arg11 = %19, %arg12 = %15) : (index, index, f32) -> (index, index, f32) {
          %23 = arith.cmpi ult, %arg10, %18 : index
          %24 = arith.cmpi ult, %arg11, %21 : index
          %25 = arith.andi %23, %24 : i1
          scf.condition(%25) %arg10, %arg11, %arg12 : index, index, f32
        } do {
        ^bb0(%arg10: index, %arg11: index, %arg12: f32):
          %23 = memref.load %arg1[%arg10] : memref<?xindex>
          %24 = memref.load %arg5[%arg11] : memref<?xindex>
          %25 = arith.cmpi ult, %24, %23 : index
          %26 = arith.select %25, %24, %23 : index
          %27 = arith.cmpi eq, %23, %26 : index
          %28 = arith.cmpi eq, %24, %26 : index
          %29 = arith.andi %27, %28 : i1
          %30 = scf.if %29 -> (f32) {
            %37 = memref.load %arg2[%arg10] : memref<?xf32>
            %38 = memref.load %arg6[%arg11] : memref<?xf32>
            %39 = arith.mulf %37, %38 : f32
            %40 = arith.addf %arg12, %39 : f32
            scf.yield %40 : f32
          } else {
            scf.yield %arg12 : f32
          }
          %31 = arith.cmpi eq, %23, %26 : index
          %32 = arith.addi %arg10, %c1 : index
          %33 = arith.select %31, %32, %arg10 : index
          %34 = arith.cmpi eq, %24, %26 : index
          %35 = arith.addi %arg11, %c1 : index
          %36 = arith.select %34, %35, %arg11 : index
          scf.yield %33, %36, %30 : index, index, f32
        } attributes {"Emitted from" = "linalg.generic"}
        memref.store %22#2, %10[%14] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %10, %12 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c240_i64 = arith.constant 240 : i64
  %c0 = arith.constant 0 : index
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %alloc = memref.alloc() : memref<240xf32>
  %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  linalg.fill ins(%cst : f32) outs(%alloc : memref<240xf32>)
  %4 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.parallel (%arg8, %arg9) = (%c0, %c0) to (%c15, %c16) step (%c1, %c1) {
    %5 = arith.muli %arg8, %c16 : index
    %6 = arith.addi %5, %arg9 : index
    %7 = memref.load %alloc[%6] : memref<240xf32>
    %8 = memref.load %arg0[%arg8] : memref<?xindex>
    %9 = arith.addi %arg8, %c1 : index
    %10 = memref.load %arg0[%9] : memref<?xindex>
    %11 = memref.load %arg4[%arg9] : memref<?xindex>
    %12 = arith.addi %arg9, %c1 : index
    %13 = memref.load %arg4[%12] : memref<?xindex>
    %14:3 = scf.while (%arg10 = %8, %arg11 = %11, %arg12 = %7) : (index, index, f32) -> (index, index, f32) {
      %15 = arith.cmpi ult, %arg10, %10 : index
      %16 = arith.cmpi ult, %arg11, %13 : index
      %17 = arith.andi %15, %16 : i1
      scf.condition(%17) %arg10, %arg11, %arg12 : index, index, f32
    } do {
    ^bb0(%arg10: index, %arg11: index, %arg12: f32):
      %15 = memref.load %arg1[%arg10] : memref<?xindex>
      %16 = memref.load %arg5[%arg11] : memref<?xindex>
      %17 = arith.cmpi ult, %16, %15 : index
      %18 = arith.select %17, %16, %15 : index
      %19 = arith.cmpi eq, %15, %18 : index
      %20 = arith.cmpi eq, %16, %18 : index
      %21 = arith.andi %19, %20 : i1
      %22 = scf.if %21 -> (f32) {
        %29 = memref.load %arg2[%arg10] : memref<?xf32>
        %30 = memref.load %arg6[%arg11] : memref<?xf32>
        %31 = arith.mulf %29, %30 : f32
        %32 = arith.addf %arg12, %31 : f32
        scf.yield %32 : f32
      } else {
        scf.yield %arg12 : f32
      }
      %23 = arith.cmpi eq, %15, %18 : index
      %24 = arith.addi %arg10, %c1 : index
      %25 = arith.select %23, %24, %arg10 : index
      %26 = arith.cmpi eq, %16, %18 : index
      %27 = arith.addi %arg11, %c1 : index
      %28 = arith.select %26, %27, %arg11 : index
      scf.yield %25, %28, %22 : index, index, f32
    } attributes {"Emitted from" = "linalg.generic"}
    memref.store %14#2, %alloc[%6] : memref<240xf32>
    scf.yield
  }
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After FinalizingBufferize (finalizing-bufferize) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c240_i64 = arith.constant 240 : i64
  %c0 = arith.constant 0 : index
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %alloc = memref.alloc() : memref<240xf32>
  %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  linalg.fill ins(%cst : f32) outs(%alloc : memref<240xf32>)
  %4 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.parallel (%arg8, %arg9) = (%c0, %c0) to (%c15, %c16) step (%c1, %c1) {
    %5 = arith.muli %arg8, %c16 : index
    %6 = arith.addi %5, %arg9 : index
    %7 = memref.load %alloc[%6] : memref<240xf32>
    %8 = memref.load %arg0[%arg8] : memref<?xindex>
    %9 = arith.addi %arg8, %c1 : index
    %10 = memref.load %arg0[%9] : memref<?xindex>
    %11 = memref.load %arg4[%arg9] : memref<?xindex>
    %12 = arith.addi %arg9, %c1 : index
    %13 = memref.load %arg4[%12] : memref<?xindex>
    %14:3 = scf.while (%arg10 = %8, %arg11 = %11, %arg12 = %7) : (index, index, f32) -> (index, index, f32) {
      %15 = arith.cmpi ult, %arg10, %10 : index
      %16 = arith.cmpi ult, %arg11, %13 : index
      %17 = arith.andi %15, %16 : i1
      scf.condition(%17) %arg10, %arg11, %arg12 : index, index, f32
    } do {
    ^bb0(%arg10: index, %arg11: index, %arg12: f32):
      %15 = memref.load %arg1[%arg10] : memref<?xindex>
      %16 = memref.load %arg5[%arg11] : memref<?xindex>
      %17 = arith.cmpi ult, %16, %15 : index
      %18 = arith.select %17, %16, %15 : index
      %19 = arith.cmpi eq, %15, %18 : index
      %20 = arith.cmpi eq, %16, %18 : index
      %21 = arith.andi %19, %20 : i1
      %22 = scf.if %21 -> (f32) {
        %29 = memref.load %arg2[%arg10] : memref<?xf32>
        %30 = memref.load %arg6[%arg11] : memref<?xf32>
        %31 = arith.mulf %29, %30 : f32
        %32 = arith.addf %arg12, %31 : f32
        scf.yield %32 : f32
      } else {
        scf.yield %arg12 : f32
      }
      %23 = arith.cmpi eq, %15, %18 : index
      %24 = arith.addi %arg10, %c1 : index
      %25 = arith.select %23, %24, %arg10 : index
      %26 = arith.cmpi eq, %16, %18 : index
      %27 = arith.addi %arg11, %c1 : index
      %28 = arith.select %26, %27, %arg11 : index
      scf.yield %25, %28, %22 : index, index, f32
    } attributes {"Emitted from" = "linalg.generic"}
    memref.store %14#2, %alloc[%6] : memref<240xf32>
    scf.yield
  }
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c240 = arith.constant 240 : index
  %c1 = arith.constant 1 : index
  %c240_i64 = arith.constant 240 : i64
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %alloc = memref.alloc() : memref<240xf32>
  %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.for %arg8 = %c0 to %c240 step %c1 {
    memref.store %cst, %alloc[%arg8] : memref<240xf32>
  }
  %4 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.parallel (%arg8, %arg9) = (%c0, %c0) to (%c15, %c16) step (%c1, %c1) {
    %5 = arith.muli %arg8, %c16 : index
    %6 = arith.addi %5, %arg9 : index
    %7 = memref.load %alloc[%6] : memref<240xf32>
    %8 = memref.load %arg0[%arg8] : memref<?xindex>
    %9 = arith.addi %arg8, %c1 : index
    %10 = memref.load %arg0[%9] : memref<?xindex>
    %11 = memref.load %arg4[%arg9] : memref<?xindex>
    %12 = arith.addi %arg9, %c1 : index
    %13 = memref.load %arg4[%12] : memref<?xindex>
    %14:3 = scf.while (%arg10 = %8, %arg11 = %11, %arg12 = %7) : (index, index, f32) -> (index, index, f32) {
      %15 = arith.cmpi ult, %arg10, %10 : index
      %16 = arith.cmpi ult, %arg11, %13 : index
      %17 = arith.andi %15, %16 : i1
      scf.condition(%17) %arg10, %arg11, %arg12 : index, index, f32
    } do {
    ^bb0(%arg10: index, %arg11: index, %arg12: f32):
      %15 = memref.load %arg1[%arg10] : memref<?xindex>
      %16 = memref.load %arg5[%arg11] : memref<?xindex>
      %17 = arith.cmpi ult, %16, %15 : index
      %18 = arith.select %17, %16, %15 : index
      %19 = arith.cmpi eq, %15, %18 : index
      %20 = arith.cmpi eq, %16, %18 : index
      %21 = arith.andi %19, %20 : i1
      %22 = scf.if %21 -> (f32) {
        %29 = memref.load %arg2[%arg10] : memref<?xf32>
        %30 = memref.load %arg6[%arg11] : memref<?xf32>
        %31 = arith.mulf %29, %30 : f32
        %32 = arith.addf %arg12, %31 : f32
        scf.yield %32 : f32
      } else {
        scf.yield %arg12 : f32
      }
      %23 = arith.cmpi eq, %15, %18 : index
      %24 = arith.addi %arg10, %c1 : index
      %25 = arith.select %23, %24, %arg10 : index
      %26 = arith.cmpi eq, %16, %18 : index
      %27 = arith.addi %arg11, %c1 : index
      %28 = arith.select %26, %27, %arg11 : index
      scf.yield %25, %28, %22 : index, index, f32
    } attributes {"Emitted from" = "linalg.generic"}
    memref.store %14#2, %alloc[%6] : memref<240xf32>
    scf.yield
  }
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertVectorToSCF (convert-vector-to-scf) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c240 = arith.constant 240 : index
  %c1 = arith.constant 1 : index
  %c240_i64 = arith.constant 240 : i64
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %alloc = memref.alloc() : memref<240xf32>
  %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.for %arg8 = %c0 to %c240 step %c1 {
    memref.store %cst, %alloc[%arg8] : memref<240xf32>
  }
  %4 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.parallel (%arg8, %arg9) = (%c0, %c0) to (%c15, %c16) step (%c1, %c1) {
    %5 = arith.muli %arg8, %c16 : index
    %6 = arith.addi %5, %arg9 : index
    %7 = memref.load %alloc[%6] : memref<240xf32>
    %8 = memref.load %arg0[%arg8] : memref<?xindex>
    %9 = arith.addi %arg8, %c1 : index
    %10 = memref.load %arg0[%9] : memref<?xindex>
    %11 = memref.load %arg4[%arg9] : memref<?xindex>
    %12 = arith.addi %arg9, %c1 : index
    %13 = memref.load %arg4[%12] : memref<?xindex>
    %14:3 = scf.while (%arg10 = %8, %arg11 = %11, %arg12 = %7) : (index, index, f32) -> (index, index, f32) {
      %15 = arith.cmpi ult, %arg10, %10 : index
      %16 = arith.cmpi ult, %arg11, %13 : index
      %17 = arith.andi %15, %16 : i1
      scf.condition(%17) %arg10, %arg11, %arg12 : index, index, f32
    } do {
    ^bb0(%arg10: index, %arg11: index, %arg12: f32):
      %15 = memref.load %arg1[%arg10] : memref<?xindex>
      %16 = memref.load %arg5[%arg11] : memref<?xindex>
      %17 = arith.cmpi ult, %16, %15 : index
      %18 = arith.select %17, %16, %15 : index
      %19 = arith.cmpi eq, %15, %18 : index
      %20 = arith.cmpi eq, %16, %18 : index
      %21 = arith.andi %19, %20 : i1
      %22 = scf.if %21 -> (f32) {
        %29 = memref.load %arg2[%arg10] : memref<?xf32>
        %30 = memref.load %arg6[%arg11] : memref<?xf32>
        %31 = arith.mulf %29, %30 : f32
        %32 = arith.addf %arg12, %31 : f32
        scf.yield %32 : f32
      } else {
        scf.yield %arg12 : f32
      }
      %23 = arith.cmpi eq, %15, %18 : index
      %24 = arith.addi %arg10, %c1 : index
      %25 = arith.select %23, %24, %arg10 : index
      %26 = arith.cmpi eq, %16, %18 : index
      %27 = arith.addi %arg11, %c1 : index
      %28 = arith.select %26, %27, %arg11 : index
      scf.yield %25, %28, %22 : index, index, f32
    } attributes {"Emitted from" = "linalg.generic"}
    memref.store %14#2, %alloc[%6] : memref<240xf32>
    scf.yield
  }
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c240 = arith.constant 240 : index
  %c1 = arith.constant 1 : index
  %c240_i64 = arith.constant 240 : i64
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %alloc = memref.alloc() : memref<240xf32>
  %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%4: index):  // 2 preds: ^bb0, ^bb2
  %5 = arith.cmpi slt, %4, %c240 : index
  cf.cond_br %5, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  memref.store %cst, %alloc[%4] : memref<240xf32>
  %6 = arith.addi %4, %c1 : index
  cf.br ^bb1(%6 : index)
^bb3:  // pred: ^bb1
  %7 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb4(%c0 : index)
^bb4(%8: index):  // 2 preds: ^bb3, ^bb15
  %9 = arith.cmpi slt, %8, %c15 : index
  cf.cond_br %9, ^bb5, ^bb16
^bb5:  // pred: ^bb4
  cf.br ^bb6(%c0 : index)
^bb6(%10: index):  // 2 preds: ^bb5, ^bb14
  %11 = arith.cmpi slt, %10, %c16 : index
  cf.cond_br %11, ^bb7, ^bb15
^bb7:  // pred: ^bb6
  %12 = arith.muli %8, %c16 : index
  %13 = arith.addi %12, %10 : index
  %14 = memref.load %alloc[%13] : memref<240xf32>
  %15 = memref.load %arg0[%8] : memref<?xindex>
  %16 = arith.addi %8, %c1 : index
  %17 = memref.load %arg0[%16] : memref<?xindex>
  %18 = memref.load %arg4[%10] : memref<?xindex>
  %19 = arith.addi %10, %c1 : index
  %20 = memref.load %arg4[%19] : memref<?xindex>
  cf.br ^bb8(%15, %18, %14 : index, index, f32)
^bb8(%21: index, %22: index, %23: f32):  // 2 preds: ^bb7, ^bb13
  %24 = arith.cmpi ult, %21, %17 : index
  %25 = arith.cmpi ult, %22, %20 : index
  %26 = arith.andi %24, %25 : i1
  cf.cond_br %26, ^bb9(%21, %22, %23 : index, index, f32), ^bb14
^bb9(%27: index, %28: index, %29: f32):  // pred: ^bb8
  %30 = memref.load %arg1[%27] : memref<?xindex>
  %31 = memref.load %arg5[%28] : memref<?xindex>
  %32 = arith.cmpi ult, %31, %30 : index
  %33 = arith.select %32, %31, %30 : index
  %34 = arith.cmpi eq, %30, %33 : index
  %35 = arith.cmpi eq, %31, %33 : index
  %36 = arith.andi %34, %35 : i1
  cf.cond_br %36, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %37 = memref.load %arg2[%27] : memref<?xf32>
  %38 = memref.load %arg6[%28] : memref<?xf32>
  %39 = arith.mulf %37, %38 : f32
  %40 = arith.addf %29, %39 : f32
  cf.br ^bb12(%40 : f32)
^bb11:  // pred: ^bb9
  cf.br ^bb12(%29 : f32)
^bb12(%41: f32):  // 2 preds: ^bb10, ^bb11
  cf.br ^bb13
^bb13:  // pred: ^bb12
  %42 = arith.cmpi eq, %30, %33 : index
  %43 = arith.addi %27, %c1 : index
  %44 = arith.select %42, %43, %27 : index
  %45 = arith.cmpi eq, %31, %33 : index
  %46 = arith.addi %28, %c1 : index
  %47 = arith.select %45, %46, %28 : index
  cf.br ^bb8(%44, %47, %41 : index, index, f32)
^bb14:  // pred: ^bb8
  memref.store %23, %alloc[%13] : memref<240xf32>
  %48 = arith.addi %10, %c1 : index
  cf.br ^bb6(%48 : index)
^bb15:  // pred: ^bb6
  %49 = arith.addi %8, %c1 : index
  cf.br ^bb4(%49 : index)
^bb16:  // pred: ^bb4
  return %cast, %7 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c240 = arith.constant 240 : index
    %c1 = arith.constant 1 : index
    %c240_i64 = arith.constant 240 : i64
    %c16_i64 = arith.constant 16 : i64
    %c15_i64 = arith.constant 15 : i64
    %c0_i64 = arith.constant 0 : i64
    %c15 = arith.constant 15 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %alloc = memref.alloc() : memref<240xf32>
    %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%4: index):  // 2 preds: ^bb0, ^bb2
    %5 = arith.cmpi slt, %4, %c240 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%4] : memref<240xf32>
    %6 = arith.addi %4, %c1 : index
    cf.br ^bb1(%6 : index)
  ^bb3:  // pred: ^bb1
    %7 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%8: index):  // 2 preds: ^bb3, ^bb15
    %9 = arith.cmpi slt, %8, %c15 : index
    cf.cond_br %9, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%10: index):  // 2 preds: ^bb5, ^bb14
    %11 = arith.cmpi slt, %10, %c16 : index
    cf.cond_br %11, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %12 = arith.muli %8, %c16 : index
    %13 = arith.addi %12, %10 : index
    %14 = memref.load %alloc[%13] : memref<240xf32>
    %15 = memref.load %arg0[%8] : memref<?xindex>
    %16 = arith.addi %8, %c1 : index
    %17 = memref.load %arg0[%16] : memref<?xindex>
    %18 = memref.load %arg4[%10] : memref<?xindex>
    %19 = arith.addi %10, %c1 : index
    %20 = memref.load %arg4[%19] : memref<?xindex>
    cf.br ^bb8(%15, %18, %14 : index, index, f32)
  ^bb8(%21: index, %22: index, %23: f32):  // 2 preds: ^bb7, ^bb13
    %24 = arith.cmpi ult, %21, %17 : index
    %25 = arith.cmpi ult, %22, %20 : index
    %26 = arith.andi %24, %25 : i1
    cf.cond_br %26, ^bb9(%21, %22, %23 : index, index, f32), ^bb14
  ^bb9(%27: index, %28: index, %29: f32):  // pred: ^bb8
    %30 = memref.load %arg1[%27] : memref<?xindex>
    %31 = memref.load %arg5[%28] : memref<?xindex>
    %32 = arith.cmpi ult, %31, %30 : index
    %33 = arith.select %32, %31, %30 : index
    %34 = arith.cmpi eq, %30, %33 : index
    %35 = arith.cmpi eq, %31, %33 : index
    %36 = arith.andi %34, %35 : i1
    cf.cond_br %36, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %37 = memref.load %arg2[%27] : memref<?xf32>
    %38 = memref.load %arg6[%28] : memref<?xf32>
    %39 = arith.mulf %37, %38 : f32
    %40 = arith.addf %29, %39 : f32
    cf.br ^bb12(%40 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%29 : f32)
  ^bb12(%41: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %42 = arith.cmpi eq, %30, %33 : index
    %43 = arith.addi %27, %c1 : index
    %44 = arith.select %42, %43, %27 : index
    %45 = arith.cmpi eq, %31, %33 : index
    %46 = arith.addi %28, %c1 : index
    %47 = arith.select %45, %46, %28 : index
    cf.br ^bb8(%44, %47, %41 : index, index, f32)
  ^bb14:  // pred: ^bb8
    memref.store %23, %alloc[%13] : memref<240xf32>
    %48 = arith.addi %10, %c1 : index
    cf.br ^bb6(%48 : index)
  ^bb15:  // pred: ^bb6
    %49 = arith.addi %8, %c1 : index
    cf.br ^bb4(%49 : index)
  ^bb16:  // pred: ^bb4
    return %cast, %7 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c240 = arith.constant 240 : index
    %c1 = arith.constant 1 : index
    %c240_i64 = arith.constant 240 : i64
    %c16_i64 = arith.constant 16 : i64
    %c15_i64 = arith.constant 15 : i64
    %c0_i64 = arith.constant 0 : i64
    %c15 = arith.constant 15 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %alloc = memref.alloc() : memref<240xf32>
    %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%4: index):  // 2 preds: ^bb0, ^bb2
    %5 = arith.cmpi slt, %4, %c240 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%4] : memref<240xf32>
    %6 = arith.addi %4, %c1 : index
    cf.br ^bb1(%6 : index)
  ^bb3:  // pred: ^bb1
    %7 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%8: index):  // 2 preds: ^bb3, ^bb15
    %9 = arith.cmpi slt, %8, %c15 : index
    cf.cond_br %9, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%10: index):  // 2 preds: ^bb5, ^bb14
    %11 = arith.cmpi slt, %10, %c16 : index
    cf.cond_br %11, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %12 = arith.muli %8, %c16 : index
    %13 = arith.addi %12, %10 : index
    %14 = memref.load %alloc[%13] : memref<240xf32>
    %15 = memref.load %arg0[%8] : memref<?xindex>
    %16 = arith.addi %8, %c1 : index
    %17 = memref.load %arg0[%16] : memref<?xindex>
    %18 = memref.load %arg4[%10] : memref<?xindex>
    %19 = arith.addi %10, %c1 : index
    %20 = memref.load %arg4[%19] : memref<?xindex>
    cf.br ^bb8(%15, %18, %14 : index, index, f32)
  ^bb8(%21: index, %22: index, %23: f32):  // 2 preds: ^bb7, ^bb13
    %24 = arith.cmpi ult, %21, %17 : index
    %25 = arith.cmpi ult, %22, %20 : index
    %26 = arith.andi %24, %25 : i1
    cf.cond_br %26, ^bb9(%21, %22, %23 : index, index, f32), ^bb14
  ^bb9(%27: index, %28: index, %29: f32):  // pred: ^bb8
    %30 = memref.load %arg1[%27] : memref<?xindex>
    %31 = memref.load %arg5[%28] : memref<?xindex>
    %32 = arith.cmpi ult, %31, %30 : index
    %33 = arith.select %32, %31, %30 : index
    %34 = arith.cmpi eq, %30, %33 : index
    %35 = arith.cmpi eq, %31, %33 : index
    %36 = arith.andi %34, %35 : i1
    cf.cond_br %36, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %37 = memref.load %arg2[%27] : memref<?xf32>
    %38 = memref.load %arg6[%28] : memref<?xf32>
    %39 = arith.mulf %37, %38 : f32
    %40 = arith.addf %29, %39 : f32
    cf.br ^bb12(%40 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%29 : f32)
  ^bb12(%41: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %42 = arith.cmpi eq, %30, %33 : index
    %43 = arith.addi %27, %c1 : index
    %44 = arith.select %42, %43, %27 : index
    %45 = arith.cmpi eq, %31, %33 : index
    %46 = arith.addi %28, %c1 : index
    %47 = arith.select %45, %46, %28 : index
    cf.br ^bb8(%44, %47, %41 : index, index, f32)
  ^bb14:  // pred: ^bb8
    memref.store %23, %alloc[%13] : memref<240xf32>
    %48 = arith.addi %10, %c1 : index
    cf.br ^bb6(%48 : index)
  ^bb15:  // pred: ^bb6
    %49 = arith.addi %8, %c1 : index
    cf.br ^bb4(%49 : index)
  ^bb16:  // pred: ^bb4
    return %cast, %7 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c240 = arith.constant 240 : index
    %c1 = arith.constant 1 : index
    %c240_i64 = arith.constant 240 : i64
    %c16_i64 = arith.constant 16 : i64
    %c15_i64 = arith.constant 15 : i64
    %c0_i64 = arith.constant 0 : i64
    %c15 = arith.constant 15 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %alloc = memref.alloc() : memref<240xf32>
    %cast = memref.cast %alloc : memref<240xf32> to memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %c15_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%4: index):  // 2 preds: ^bb0, ^bb2
    %5 = arith.cmpi slt, %4, %c240 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%4] : memref<240xf32>
    %6 = arith.addi %4, %c1 : index
    cf.br ^bb1(%6 : index)
  ^bb3:  // pred: ^bb1
    %7 = llvm.insertvalue %c240_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%8: index):  // 2 preds: ^bb3, ^bb15
    %9 = arith.cmpi slt, %8, %c15 : index
    cf.cond_br %9, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%10: index):  // 2 preds: ^bb5, ^bb14
    %11 = arith.cmpi slt, %10, %c16 : index
    cf.cond_br %11, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %12 = arith.muli %8, %c16 : index
    %13 = arith.addi %12, %10 : index
    %14 = memref.load %alloc[%13] : memref<240xf32>
    %15 = memref.load %arg0[%8] : memref<?xindex>
    %16 = arith.addi %8, %c1 : index
    %17 = memref.load %arg0[%16] : memref<?xindex>
    %18 = memref.load %arg4[%10] : memref<?xindex>
    %19 = arith.addi %10, %c1 : index
    %20 = memref.load %arg4[%19] : memref<?xindex>
    cf.br ^bb8(%15, %18, %14 : index, index, f32)
  ^bb8(%21: index, %22: index, %23: f32):  // 2 preds: ^bb7, ^bb13
    %24 = arith.cmpi ult, %21, %17 : index
    %25 = arith.cmpi ult, %22, %20 : index
    %26 = arith.andi %24, %25 : i1
    cf.cond_br %26, ^bb9(%21, %22, %23 : index, index, f32), ^bb14
  ^bb9(%27: index, %28: index, %29: f32):  // pred: ^bb8
    %30 = memref.load %arg1[%27] : memref<?xindex>
    %31 = memref.load %arg5[%28] : memref<?xindex>
    %32 = arith.cmpi ult, %31, %30 : index
    %33 = arith.select %32, %31, %30 : index
    %34 = arith.cmpi eq, %30, %33 : index
    %35 = arith.cmpi eq, %31, %33 : index
    %36 = arith.andi %34, %35 : i1
    cf.cond_br %36, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %37 = memref.load %arg2[%27] : memref<?xf32>
    %38 = memref.load %arg6[%28] : memref<?xf32>
    %39 = arith.mulf %37, %38 : f32
    %40 = arith.addf %29, %39 : f32
    cf.br ^bb12(%40 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%29 : f32)
  ^bb12(%41: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %42 = arith.cmpi eq, %30, %33 : index
    %43 = arith.addi %27, %c1 : index
    %44 = arith.select %42, %43, %27 : index
    %45 = arith.cmpi eq, %31, %33 : index
    %46 = arith.addi %28, %c1 : index
    %47 = arith.select %45, %46, %28 : index
    cf.br ^bb8(%44, %47, %41 : index, index, f32)
  ^bb14:  // pred: ^bb8
    memref.store %23, %alloc[%13] : memref<240xf32>
    %48 = arith.addi %10, %c1 : index
    cf.br ^bb6(%48 : index)
  ^bb15:  // pred: ^bb6
    %49 = arith.addi %8, %c1 : index
    cf.br ^bb4(%49 : index)
  ^bb16:  // pred: ^bb4
    return %cast, %7 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After FinalizeMemRefToLLVMConversionPass (finalize-memref-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %c0 = arith.constant 0 : index
    %c240 = arith.constant 240 : index
    %c1 = arith.constant 1 : index
    %c240_i64 = arith.constant 240 : i64
    %c16_i64 = arith.constant 16 : i64
    %c15_i64 = arith.constant 15 : i64
    %c0_i64 = arith.constant 0 : i64
    %c15 = arith.constant 15 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %6 = llvm.mlir.constant(240 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.null : !llvm.ptr
    %9 = llvm.getelementptr %8[%6] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %10 = llvm.ptrtoint %9 : !llvm.ptr to i64
    %11 = llvm.call @malloc(%10) : (i64) -> !llvm.ptr
    %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.insertvalue %11, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.mlir.constant(0 : index) : i64
    %16 = llvm.insertvalue %15, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %6, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
    %25 = builtin.unrealized_conversion_cast %24 : index to i64
    %26 = arith.cmpi slt, %24, %c240 : index
    cf.cond_br %26, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %27 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.getelementptr %27[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %28 : f32, !llvm.ptr
    %29 = arith.addi %24, %c1 : index
    cf.br ^bb1(%29 : index)
  ^bb3:  // pred: ^bb1
    %30 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%31: index):  // 2 preds: ^bb3, ^bb15
    %32 = builtin.unrealized_conversion_cast %31 : index to i64
    %33 = arith.cmpi slt, %31, %c15 : index
    cf.cond_br %33, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%34: index):  // 2 preds: ^bb5, ^bb14
    %35 = builtin.unrealized_conversion_cast %34 : index to i64
    %36 = arith.cmpi slt, %34, %c16 : index
    cf.cond_br %36, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %37 = arith.muli %31, %c16 : index
    %38 = arith.addi %37, %34 : index
    %39 = builtin.unrealized_conversion_cast %38 : index to i64
    %40 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.getelementptr %40[%39] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %42 = llvm.load %41 : !llvm.ptr -> f32
    %43 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.getelementptr %43[%32] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %45 = llvm.load %44 : !llvm.ptr -> i64
    %46 = builtin.unrealized_conversion_cast %45 : i64 to index
    %47 = arith.addi %31, %c1 : index
    %48 = builtin.unrealized_conversion_cast %47 : index to i64
    %49 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.getelementptr %49[%48] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %51 = llvm.load %50 : !llvm.ptr -> i64
    %52 = builtin.unrealized_conversion_cast %51 : i64 to index
    %53 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.getelementptr %53[%35] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %55 = llvm.load %54 : !llvm.ptr -> i64
    %56 = builtin.unrealized_conversion_cast %55 : i64 to index
    %57 = arith.addi %34, %c1 : index
    %58 = builtin.unrealized_conversion_cast %57 : index to i64
    %59 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.getelementptr %59[%58] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %61 = llvm.load %60 : !llvm.ptr -> i64
    %62 = builtin.unrealized_conversion_cast %61 : i64 to index
    cf.br ^bb8(%46, %56, %42 : index, index, f32)
  ^bb8(%63: index, %64: index, %65: f32):  // 2 preds: ^bb7, ^bb13
    %66 = arith.cmpi ult, %63, %52 : index
    %67 = arith.cmpi ult, %64, %62 : index
    %68 = arith.andi %66, %67 : i1
    cf.cond_br %68, ^bb9(%63, %64, %65 : index, index, f32), ^bb14
  ^bb9(%69: index, %70: index, %71: f32):  // pred: ^bb8
    %72 = builtin.unrealized_conversion_cast %69 : index to i64
    %73 = builtin.unrealized_conversion_cast %70 : index to i64
    %74 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %75 = llvm.getelementptr %74[%72] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %76 = llvm.load %75 : !llvm.ptr -> i64
    %77 = builtin.unrealized_conversion_cast %76 : i64 to index
    %78 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %79 = llvm.getelementptr %78[%73] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %80 = llvm.load %79 : !llvm.ptr -> i64
    %81 = builtin.unrealized_conversion_cast %80 : i64 to index
    %82 = arith.cmpi ult, %81, %77 : index
    %83 = arith.select %82, %81, %77 : index
    %84 = arith.cmpi eq, %77, %83 : index
    %85 = arith.cmpi eq, %81, %83 : index
    %86 = arith.andi %84, %85 : i1
    cf.cond_br %86, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %87 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %88 = llvm.getelementptr %87[%72] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %89 = llvm.load %88 : !llvm.ptr -> f32
    %90 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %91 = llvm.getelementptr %90[%73] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %92 = llvm.load %91 : !llvm.ptr -> f32
    %93 = arith.mulf %89, %92 : f32
    %94 = arith.addf %71, %93 : f32
    cf.br ^bb12(%94 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%71 : f32)
  ^bb12(%95: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %96 = arith.cmpi eq, %77, %83 : index
    %97 = arith.addi %69, %c1 : index
    %98 = arith.select %96, %97, %69 : index
    %99 = arith.cmpi eq, %81, %83 : index
    %100 = arith.addi %70, %c1 : index
    %101 = arith.select %99, %100, %70 : index
    cf.br ^bb8(%98, %101, %95 : index, index, f32)
  ^bb14:  // pred: ^bb8
    %102 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %103 = llvm.getelementptr %102[%39] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %65, %103 : f32, !llvm.ptr
    %104 = arith.addi %34, %c1 : index
    cf.br ^bb6(%104 : index)
  ^bb15:  // pred: ^bb6
    %105 = arith.addi %31, %c1 : index
    cf.br ^bb4(%105 : index)
  ^bb16:  // pred: ^bb4
    return %19, %30 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToStandard (convert-complex-to-standard) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %c0 = arith.constant 0 : index
  %c240 = arith.constant 240 : index
  %c1 = arith.constant 1 : index
  %c240_i64 = arith.constant 240 : i64
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %6 = llvm.mlir.constant(240 : index) : i64
  %7 = llvm.mlir.constant(1 : index) : i64
  %8 = llvm.mlir.null : !llvm.ptr
  %9 = llvm.getelementptr %8[240] : (!llvm.ptr) -> !llvm.ptr, f32
  %10 = llvm.ptrtoint %9 : !llvm.ptr to i64
  %11 = llvm.call @malloc(%10) : (i64) -> !llvm.ptr
  %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %13 = llvm.insertvalue %11, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %15 = llvm.mlir.constant(0 : index) : i64
  %16 = llvm.insertvalue %15, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %17 = llvm.insertvalue %6, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %18 = llvm.insertvalue %7, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
  %25 = builtin.unrealized_conversion_cast %24 : index to i64
  %26 = arith.cmpi slt, %24, %c240 : index
  cf.cond_br %26, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %27 = llvm.getelementptr %11[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %27 : f32, !llvm.ptr
  %28 = arith.addi %24, %c1 : index
  cf.br ^bb1(%28 : index)
^bb3:  // pred: ^bb1
  %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb4(%c0 : index)
^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
  %31 = builtin.unrealized_conversion_cast %30 : index to i64
  %32 = arith.cmpi slt, %30, %c15 : index
  cf.cond_br %32, ^bb5, ^bb16
^bb5:  // pred: ^bb4
  cf.br ^bb6(%c0 : index)
^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
  %34 = builtin.unrealized_conversion_cast %33 : index to i64
  %35 = arith.cmpi slt, %33, %c16 : index
  cf.cond_br %35, ^bb7, ^bb15
^bb7:  // pred: ^bb6
  %36 = arith.muli %30, %c16 : index
  %37 = arith.addi %36, %33 : index
  %38 = builtin.unrealized_conversion_cast %37 : index to i64
  %39 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %40 = llvm.load %39 : !llvm.ptr -> f32
  %41 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %43 = llvm.load %42 : !llvm.ptr -> i64
  %44 = builtin.unrealized_conversion_cast %43 : i64 to index
  %45 = arith.addi %30, %c1 : index
  %46 = builtin.unrealized_conversion_cast %45 : index to i64
  %47 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %49 = llvm.load %48 : !llvm.ptr -> i64
  %50 = builtin.unrealized_conversion_cast %49 : i64 to index
  %51 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %53 = llvm.load %52 : !llvm.ptr -> i64
  %54 = builtin.unrealized_conversion_cast %53 : i64 to index
  %55 = arith.addi %33, %c1 : index
  %56 = builtin.unrealized_conversion_cast %55 : index to i64
  %57 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %59 = llvm.load %58 : !llvm.ptr -> i64
  %60 = builtin.unrealized_conversion_cast %59 : i64 to index
  cf.br ^bb8(%44, %54, %40 : index, index, f32)
^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
  %64 = arith.cmpi ult, %61, %50 : index
  %65 = arith.cmpi ult, %62, %60 : index
  %66 = arith.andi %64, %65 : i1
  cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
  %70 = builtin.unrealized_conversion_cast %67 : index to i64
  %71 = builtin.unrealized_conversion_cast %68 : index to i64
  %72 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %74 = llvm.load %73 : !llvm.ptr -> i64
  %75 = builtin.unrealized_conversion_cast %74 : i64 to index
  %76 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %78 = llvm.load %77 : !llvm.ptr -> i64
  %79 = builtin.unrealized_conversion_cast %78 : i64 to index
  %80 = arith.cmpi ult, %79, %75 : index
  %81 = arith.select %80, %79, %75 : index
  %82 = arith.cmpi eq, %75, %81 : index
  %83 = arith.cmpi eq, %79, %81 : index
  %84 = arith.andi %82, %83 : i1
  cf.cond_br %84, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %85 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %87 = llvm.load %86 : !llvm.ptr -> f32
  %88 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %90 = llvm.load %89 : !llvm.ptr -> f32
  %91 = arith.mulf %87, %90 : f32
  %92 = arith.addf %69, %91 : f32
  cf.br ^bb12(%92 : f32)
^bb11:  // pred: ^bb9
  cf.br ^bb12(%69 : f32)
^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
  cf.br ^bb13
^bb13:  // pred: ^bb12
  %94 = arith.cmpi eq, %75, %81 : index
  %95 = arith.addi %67, %c1 : index
  %96 = arith.select %94, %95, %67 : index
  %97 = arith.cmpi eq, %79, %81 : index
  %98 = arith.addi %68, %c1 : index
  %99 = arith.select %97, %98, %68 : index
  cf.br ^bb8(%96, %99, %93 : index, index, f32)
^bb14:  // pred: ^bb8
  %100 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %63, %100 : f32, !llvm.ptr
  %101 = arith.addi %33, %c1 : index
  cf.br ^bb6(%101 : index)
^bb15:  // pred: ^bb6
  %102 = arith.addi %30, %c1 : index
  cf.br ^bb4(%102 : index)
^bb16:  // pred: ^bb4
  return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %c0 = arith.constant 0 : index
  %c240 = arith.constant 240 : index
  %c1 = arith.constant 1 : index
  %c240_i64 = arith.constant 240 : i64
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %6 = llvm.mlir.constant(240 : index) : i64
  %7 = llvm.mlir.constant(1 : index) : i64
  %8 = llvm.mlir.null : !llvm.ptr
  %9 = llvm.getelementptr %8[240] : (!llvm.ptr) -> !llvm.ptr, f32
  %10 = llvm.ptrtoint %9 : !llvm.ptr to i64
  %11 = llvm.call @malloc(%10) : (i64) -> !llvm.ptr
  %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %13 = llvm.insertvalue %11, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %15 = llvm.mlir.constant(0 : index) : i64
  %16 = llvm.insertvalue %15, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %17 = llvm.insertvalue %6, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %18 = llvm.insertvalue %7, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
  %25 = builtin.unrealized_conversion_cast %24 : index to i64
  %26 = arith.cmpi slt, %24, %c240 : index
  cf.cond_br %26, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %27 = llvm.getelementptr %11[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %27 : f32, !llvm.ptr
  %28 = arith.addi %24, %c1 : index
  cf.br ^bb1(%28 : index)
^bb3:  // pred: ^bb1
  %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb4(%c0 : index)
^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
  %31 = builtin.unrealized_conversion_cast %30 : index to i64
  %32 = arith.cmpi slt, %30, %c15 : index
  cf.cond_br %32, ^bb5, ^bb16
^bb5:  // pred: ^bb4
  cf.br ^bb6(%c0 : index)
^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
  %34 = builtin.unrealized_conversion_cast %33 : index to i64
  %35 = arith.cmpi slt, %33, %c16 : index
  cf.cond_br %35, ^bb7, ^bb15
^bb7:  // pred: ^bb6
  %36 = arith.muli %30, %c16 : index
  %37 = arith.addi %36, %33 : index
  %38 = builtin.unrealized_conversion_cast %37 : index to i64
  %39 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %40 = llvm.load %39 : !llvm.ptr -> f32
  %41 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %43 = llvm.load %42 : !llvm.ptr -> i64
  %44 = builtin.unrealized_conversion_cast %43 : i64 to index
  %45 = arith.addi %30, %c1 : index
  %46 = builtin.unrealized_conversion_cast %45 : index to i64
  %47 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %49 = llvm.load %48 : !llvm.ptr -> i64
  %50 = builtin.unrealized_conversion_cast %49 : i64 to index
  %51 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %53 = llvm.load %52 : !llvm.ptr -> i64
  %54 = builtin.unrealized_conversion_cast %53 : i64 to index
  %55 = arith.addi %33, %c1 : index
  %56 = builtin.unrealized_conversion_cast %55 : index to i64
  %57 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %59 = llvm.load %58 : !llvm.ptr -> i64
  %60 = builtin.unrealized_conversion_cast %59 : i64 to index
  cf.br ^bb8(%44, %54, %40 : index, index, f32)
^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
  %64 = arith.cmpi ult, %61, %50 : index
  %65 = arith.cmpi ult, %62, %60 : index
  %66 = arith.andi %64, %65 : i1
  cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
  %70 = builtin.unrealized_conversion_cast %67 : index to i64
  %71 = builtin.unrealized_conversion_cast %68 : index to i64
  %72 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %74 = llvm.load %73 : !llvm.ptr -> i64
  %75 = builtin.unrealized_conversion_cast %74 : i64 to index
  %76 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %78 = llvm.load %77 : !llvm.ptr -> i64
  %79 = builtin.unrealized_conversion_cast %78 : i64 to index
  %80 = arith.cmpi ult, %79, %75 : index
  %81 = arith.select %80, %79, %75 : index
  %82 = arith.cmpi eq, %75, %81 : index
  %83 = arith.cmpi eq, %79, %81 : index
  %84 = arith.andi %82, %83 : i1
  cf.cond_br %84, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %85 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %87 = llvm.load %86 : !llvm.ptr -> f32
  %88 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %90 = llvm.load %89 : !llvm.ptr -> f32
  %91 = arith.mulf %87, %90 : f32
  %92 = arith.addf %69, %91 : f32
  cf.br ^bb12(%92 : f32)
^bb11:  // pred: ^bb9
  cf.br ^bb12(%69 : f32)
^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
  cf.br ^bb13
^bb13:  // pred: ^bb12
  %94 = arith.cmpi eq, %75, %81 : index
  %95 = arith.addi %67, %c1 : index
  %96 = arith.select %94, %95, %67 : index
  %97 = arith.cmpi eq, %79, %81 : index
  %98 = arith.addi %68, %c1 : index
  %99 = arith.select %97, %98, %68 : index
  cf.br ^bb8(%96, %99, %93 : index, index, f32)
^bb14:  // pred: ^bb8
  %100 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %63, %100 : f32, !llvm.ptr
  %101 = arith.addi %33, %c1 : index
  cf.br ^bb6(%101 : index)
^bb15:  // pred: ^bb6
  %102 = arith.addi %30, %c1 : index
  cf.br ^bb4(%102 : index)
^bb16:  // pred: ^bb4
  return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertMathToLLVMPass (convert-math-to-llvm) //----- //
func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %c0 = arith.constant 0 : index
  %c240 = arith.constant 240 : index
  %c1 = arith.constant 1 : index
  %c240_i64 = arith.constant 240 : i64
  %c16_i64 = arith.constant 16 : i64
  %c15_i64 = arith.constant 15 : i64
  %c0_i64 = arith.constant 0 : i64
  %c15 = arith.constant 15 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c16 = arith.constant 16 : index
  %6 = llvm.mlir.constant(240 : index) : i64
  %7 = llvm.mlir.constant(1 : index) : i64
  %8 = llvm.mlir.null : !llvm.ptr
  %9 = llvm.getelementptr %8[240] : (!llvm.ptr) -> !llvm.ptr, f32
  %10 = llvm.ptrtoint %9 : !llvm.ptr to i64
  %11 = llvm.call @malloc(%10) : (i64) -> !llvm.ptr
  %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %13 = llvm.insertvalue %11, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %15 = llvm.mlir.constant(0 : index) : i64
  %16 = llvm.insertvalue %15, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %17 = llvm.insertvalue %6, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %18 = llvm.insertvalue %7, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
  %25 = builtin.unrealized_conversion_cast %24 : index to i64
  %26 = arith.cmpi slt, %24, %c240 : index
  cf.cond_br %26, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %27 = llvm.getelementptr %11[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %27 : f32, !llvm.ptr
  %28 = arith.addi %24, %c1 : index
  cf.br ^bb1(%28 : index)
^bb3:  // pred: ^bb1
  %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb4(%c0 : index)
^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
  %31 = builtin.unrealized_conversion_cast %30 : index to i64
  %32 = arith.cmpi slt, %30, %c15 : index
  cf.cond_br %32, ^bb5, ^bb16
^bb5:  // pred: ^bb4
  cf.br ^bb6(%c0 : index)
^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
  %34 = builtin.unrealized_conversion_cast %33 : index to i64
  %35 = arith.cmpi slt, %33, %c16 : index
  cf.cond_br %35, ^bb7, ^bb15
^bb7:  // pred: ^bb6
  %36 = arith.muli %30, %c16 : index
  %37 = arith.addi %36, %33 : index
  %38 = builtin.unrealized_conversion_cast %37 : index to i64
  %39 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %40 = llvm.load %39 : !llvm.ptr -> f32
  %41 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %43 = llvm.load %42 : !llvm.ptr -> i64
  %44 = builtin.unrealized_conversion_cast %43 : i64 to index
  %45 = arith.addi %30, %c1 : index
  %46 = builtin.unrealized_conversion_cast %45 : index to i64
  %47 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %49 = llvm.load %48 : !llvm.ptr -> i64
  %50 = builtin.unrealized_conversion_cast %49 : i64 to index
  %51 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %53 = llvm.load %52 : !llvm.ptr -> i64
  %54 = builtin.unrealized_conversion_cast %53 : i64 to index
  %55 = arith.addi %33, %c1 : index
  %56 = builtin.unrealized_conversion_cast %55 : index to i64
  %57 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %59 = llvm.load %58 : !llvm.ptr -> i64
  %60 = builtin.unrealized_conversion_cast %59 : i64 to index
  cf.br ^bb8(%44, %54, %40 : index, index, f32)
^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
  %64 = arith.cmpi ult, %61, %50 : index
  %65 = arith.cmpi ult, %62, %60 : index
  %66 = arith.andi %64, %65 : i1
  cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
  %70 = builtin.unrealized_conversion_cast %67 : index to i64
  %71 = builtin.unrealized_conversion_cast %68 : index to i64
  %72 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %74 = llvm.load %73 : !llvm.ptr -> i64
  %75 = builtin.unrealized_conversion_cast %74 : i64 to index
  %76 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %78 = llvm.load %77 : !llvm.ptr -> i64
  %79 = builtin.unrealized_conversion_cast %78 : i64 to index
  %80 = arith.cmpi ult, %79, %75 : index
  %81 = arith.select %80, %79, %75 : index
  %82 = arith.cmpi eq, %75, %81 : index
  %83 = arith.cmpi eq, %79, %81 : index
  %84 = arith.andi %82, %83 : i1
  cf.cond_br %84, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %85 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %87 = llvm.load %86 : !llvm.ptr -> f32
  %88 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  %90 = llvm.load %89 : !llvm.ptr -> f32
  %91 = arith.mulf %87, %90 : f32
  %92 = arith.addf %69, %91 : f32
  cf.br ^bb12(%92 : f32)
^bb11:  // pred: ^bb9
  cf.br ^bb12(%69 : f32)
^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
  cf.br ^bb13
^bb13:  // pred: ^bb12
  %94 = arith.cmpi eq, %75, %81 : index
  %95 = arith.addi %67, %c1 : index
  %96 = arith.select %94, %95, %67 : index
  %97 = arith.cmpi eq, %79, %81 : index
  %98 = arith.addi %68, %c1 : index
  %99 = arith.select %97, %98, %68 : index
  cf.br ^bb8(%96, %99, %93 : index, index, f32)
^bb14:  // pred: ^bb8
  %100 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %63, %100 : f32, !llvm.ptr
  %101 = arith.addi %33, %c1 : index
  cf.br ^bb6(%101 : index)
^bb15:  // pred: ^bb6
  %102 = arith.addi %30, %c1 : index
  cf.br ^bb4(%102 : index)
^bb16:  // pred: ^bb4
  return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertMathToLibm (convert-math-to-libm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %c0 = arith.constant 0 : index
    %c240 = arith.constant 240 : index
    %c1 = arith.constant 1 : index
    %c240_i64 = arith.constant 240 : i64
    %c16_i64 = arith.constant 16 : i64
    %c15_i64 = arith.constant 15 : i64
    %c0_i64 = arith.constant 0 : i64
    %c15 = arith.constant 15 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %6 = llvm.mlir.constant(240 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.null : !llvm.ptr
    %9 = llvm.getelementptr %8[240] : (!llvm.ptr) -> !llvm.ptr, f32
    %10 = llvm.ptrtoint %9 : !llvm.ptr to i64
    %11 = llvm.call @malloc(%10) : (i64) -> !llvm.ptr
    %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.insertvalue %11, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.mlir.constant(0 : index) : i64
    %16 = llvm.insertvalue %15, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %6, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
    %25 = builtin.unrealized_conversion_cast %24 : index to i64
    %26 = arith.cmpi slt, %24, %c240 : index
    cf.cond_br %26, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %11[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %27 : f32, !llvm.ptr
    %28 = arith.addi %24, %c1 : index
    cf.br ^bb1(%28 : index)
  ^bb3:  // pred: ^bb1
    %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c15 : index
    cf.cond_br %32, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c16 : index
    cf.cond_br %35, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %36 = arith.muli %30, %c16 : index
    %37 = arith.addi %36, %33 : index
    %38 = builtin.unrealized_conversion_cast %37 : index to i64
    %39 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %40 = llvm.load %39 : !llvm.ptr -> f32
    %41 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %43 = llvm.load %42 : !llvm.ptr -> i64
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    %45 = arith.addi %30, %c1 : index
    %46 = builtin.unrealized_conversion_cast %45 : index to i64
    %47 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %49 = llvm.load %48 : !llvm.ptr -> i64
    %50 = builtin.unrealized_conversion_cast %49 : i64 to index
    %51 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %53 = llvm.load %52 : !llvm.ptr -> i64
    %54 = builtin.unrealized_conversion_cast %53 : i64 to index
    %55 = arith.addi %33, %c1 : index
    %56 = builtin.unrealized_conversion_cast %55 : index to i64
    %57 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %59 = llvm.load %58 : !llvm.ptr -> i64
    %60 = builtin.unrealized_conversion_cast %59 : i64 to index
    cf.br ^bb8(%44, %54, %40 : index, index, f32)
  ^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
    %64 = arith.cmpi ult, %61, %50 : index
    %65 = arith.cmpi ult, %62, %60 : index
    %66 = arith.andi %64, %65 : i1
    cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
  ^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
    %70 = builtin.unrealized_conversion_cast %67 : index to i64
    %71 = builtin.unrealized_conversion_cast %68 : index to i64
    %72 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %74 = llvm.load %73 : !llvm.ptr -> i64
    %75 = builtin.unrealized_conversion_cast %74 : i64 to index
    %76 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %78 = llvm.load %77 : !llvm.ptr -> i64
    %79 = builtin.unrealized_conversion_cast %78 : i64 to index
    %80 = arith.cmpi ult, %79, %75 : index
    %81 = arith.select %80, %79, %75 : index
    %82 = arith.cmpi eq, %75, %81 : index
    %83 = arith.cmpi eq, %79, %81 : index
    %84 = arith.andi %82, %83 : i1
    cf.cond_br %84, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %85 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %87 = llvm.load %86 : !llvm.ptr -> f32
    %88 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %90 = llvm.load %89 : !llvm.ptr -> f32
    %91 = arith.mulf %87, %90 : f32
    %92 = arith.addf %69, %91 : f32
    cf.br ^bb12(%92 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%69 : f32)
  ^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %94 = arith.cmpi eq, %75, %81 : index
    %95 = arith.addi %67, %c1 : index
    %96 = arith.select %94, %95, %67 : index
    %97 = arith.cmpi eq, %79, %81 : index
    %98 = arith.addi %68, %c1 : index
    %99 = arith.select %97, %98, %68 : index
    cf.br ^bb8(%96, %99, %93 : index, index, f32)
  ^bb14:  // pred: ^bb8
    %100 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %63, %100 : f32, !llvm.ptr
    %101 = arith.addi %33, %c1 : index
    cf.br ^bb6(%101 : index)
  ^bb15:  // pred: ^bb6
    %102 = arith.addi %30, %c1 : index
    cf.br ^bb4(%102 : index)
  ^bb16:  // pred: ^bb4
    return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLibm (convert-complex-to-libm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %c0 = arith.constant 0 : index
    %c240 = arith.constant 240 : index
    %c1 = arith.constant 1 : index
    %c240_i64 = arith.constant 240 : i64
    %c16_i64 = arith.constant 16 : i64
    %c15_i64 = arith.constant 15 : i64
    %c0_i64 = arith.constant 0 : i64
    %c15 = arith.constant 15 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %6 = llvm.mlir.constant(240 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.null : !llvm.ptr
    %9 = llvm.getelementptr %8[240] : (!llvm.ptr) -> !llvm.ptr, f32
    %10 = llvm.ptrtoint %9 : !llvm.ptr to i64
    %11 = llvm.call @malloc(%10) : (i64) -> !llvm.ptr
    %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.insertvalue %11, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.mlir.constant(0 : index) : i64
    %16 = llvm.insertvalue %15, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %6, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
    %25 = builtin.unrealized_conversion_cast %24 : index to i64
    %26 = arith.cmpi slt, %24, %c240 : index
    cf.cond_br %26, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %11[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %27 : f32, !llvm.ptr
    %28 = arith.addi %24, %c1 : index
    cf.br ^bb1(%28 : index)
  ^bb3:  // pred: ^bb1
    %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c15 : index
    cf.cond_br %32, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c16 : index
    cf.cond_br %35, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %36 = arith.muli %30, %c16 : index
    %37 = arith.addi %36, %33 : index
    %38 = builtin.unrealized_conversion_cast %37 : index to i64
    %39 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %40 = llvm.load %39 : !llvm.ptr -> f32
    %41 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %43 = llvm.load %42 : !llvm.ptr -> i64
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    %45 = arith.addi %30, %c1 : index
    %46 = builtin.unrealized_conversion_cast %45 : index to i64
    %47 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %49 = llvm.load %48 : !llvm.ptr -> i64
    %50 = builtin.unrealized_conversion_cast %49 : i64 to index
    %51 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %53 = llvm.load %52 : !llvm.ptr -> i64
    %54 = builtin.unrealized_conversion_cast %53 : i64 to index
    %55 = arith.addi %33, %c1 : index
    %56 = builtin.unrealized_conversion_cast %55 : index to i64
    %57 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %59 = llvm.load %58 : !llvm.ptr -> i64
    %60 = builtin.unrealized_conversion_cast %59 : i64 to index
    cf.br ^bb8(%44, %54, %40 : index, index, f32)
  ^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
    %64 = arith.cmpi ult, %61, %50 : index
    %65 = arith.cmpi ult, %62, %60 : index
    %66 = arith.andi %64, %65 : i1
    cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
  ^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
    %70 = builtin.unrealized_conversion_cast %67 : index to i64
    %71 = builtin.unrealized_conversion_cast %68 : index to i64
    %72 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %74 = llvm.load %73 : !llvm.ptr -> i64
    %75 = builtin.unrealized_conversion_cast %74 : i64 to index
    %76 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %78 = llvm.load %77 : !llvm.ptr -> i64
    %79 = builtin.unrealized_conversion_cast %78 : i64 to index
    %80 = arith.cmpi ult, %79, %75 : index
    %81 = arith.select %80, %79, %75 : index
    %82 = arith.cmpi eq, %75, %81 : index
    %83 = arith.cmpi eq, %79, %81 : index
    %84 = arith.andi %82, %83 : i1
    cf.cond_br %84, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %85 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %87 = llvm.load %86 : !llvm.ptr -> f32
    %88 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %90 = llvm.load %89 : !llvm.ptr -> f32
    %91 = arith.mulf %87, %90 : f32
    %92 = arith.addf %69, %91 : f32
    cf.br ^bb12(%92 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%69 : f32)
  ^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %94 = arith.cmpi eq, %75, %81 : index
    %95 = arith.addi %67, %c1 : index
    %96 = arith.select %94, %95, %67 : index
    %97 = arith.cmpi eq, %79, %81 : index
    %98 = arith.addi %68, %c1 : index
    %99 = arith.select %97, %98, %68 : index
    cf.br ^bb8(%96, %99, %93 : index, index, f32)
  ^bb14:  // pred: ^bb8
    %100 = llvm.getelementptr %11[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %63, %100 : f32, !llvm.ptr
    %101 = arith.addi %33, %c1 : index
    cf.br ^bb6(%101 : index)
  ^bb15:  // pred: ^bb6
    %102 = arith.addi %30, %c1 : index
    cf.br ^bb4(%102 : index)
  ^bb16:  // pred: ^bb4
    return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(240 : index) : i64
    %c16 = arith.constant 16 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c15 = arith.constant 15 : index
    %c0_i64 = arith.constant 0 : i64
    %c15_i64 = arith.constant 15 : i64
    %c16_i64 = arith.constant 16 : i64
    %c240_i64 = arith.constant 240 : i64
    %c1 = arith.constant 1 : index
    %c240 = arith.constant 240 : index
    %c0 = arith.constant 0 : index
    %3 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = llvm.mlir.null : !llvm.ptr
    %10 = llvm.getelementptr %9[240] : (!llvm.ptr) -> !llvm.ptr, f32
    %11 = llvm.ptrtoint %10 : !llvm.ptr to i64
    %12 = llvm.call @malloc(%11) : (i64) -> !llvm.ptr
    %13 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %14 = llvm.insertvalue %12, %13[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %12, %14[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %0, %15[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %2, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
    %25 = builtin.unrealized_conversion_cast %24 : index to i64
    %26 = arith.cmpi slt, %24, %c240 : index
    cf.cond_br %26, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %12[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %27 : f32, !llvm.ptr
    %28 = arith.addi %24, %c1 : index
    cf.br ^bb1(%28 : index)
  ^bb3:  // pred: ^bb1
    %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c15 : index
    cf.cond_br %32, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c16 : index
    cf.cond_br %35, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %36 = arith.muli %30, %c16 : index
    %37 = arith.addi %36, %33 : index
    %38 = builtin.unrealized_conversion_cast %37 : index to i64
    %39 = llvm.getelementptr %12[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %40 = llvm.load %39 : !llvm.ptr -> f32
    %41 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %43 = llvm.load %42 : !llvm.ptr -> i64
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    %45 = arith.addi %30, %c1 : index
    %46 = builtin.unrealized_conversion_cast %45 : index to i64
    %47 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %49 = llvm.load %48 : !llvm.ptr -> i64
    %50 = builtin.unrealized_conversion_cast %49 : i64 to index
    %51 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %53 = llvm.load %52 : !llvm.ptr -> i64
    %54 = builtin.unrealized_conversion_cast %53 : i64 to index
    %55 = arith.addi %33, %c1 : index
    %56 = builtin.unrealized_conversion_cast %55 : index to i64
    %57 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %59 = llvm.load %58 : !llvm.ptr -> i64
    %60 = builtin.unrealized_conversion_cast %59 : i64 to index
    cf.br ^bb8(%44, %54, %40 : index, index, f32)
  ^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
    %64 = arith.cmpi ult, %61, %50 : index
    %65 = arith.cmpi ult, %62, %60 : index
    %66 = arith.andi %64, %65 : i1
    cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
  ^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
    %70 = builtin.unrealized_conversion_cast %67 : index to i64
    %71 = builtin.unrealized_conversion_cast %68 : index to i64
    %72 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %74 = llvm.load %73 : !llvm.ptr -> i64
    %75 = builtin.unrealized_conversion_cast %74 : i64 to index
    %76 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %78 = llvm.load %77 : !llvm.ptr -> i64
    %79 = builtin.unrealized_conversion_cast %78 : i64 to index
    %80 = arith.cmpi ult, %79, %75 : index
    %81 = arith.select %80, %79, %75 : index
    %82 = arith.cmpi eq, %75, %81 : index
    %83 = arith.cmpi eq, %79, %81 : index
    %84 = arith.andi %82, %83 : i1
    cf.cond_br %84, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %85 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %87 = llvm.load %86 : !llvm.ptr -> f32
    %88 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %90 = llvm.load %89 : !llvm.ptr -> f32
    %91 = arith.mulf %87, %90 : f32
    %92 = arith.addf %69, %91 : f32
    cf.br ^bb12(%92 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%69 : f32)
  ^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %94 = arith.cmpi eq, %75, %81 : index
    %95 = arith.addi %67, %c1 : index
    %96 = arith.select %94, %95, %67 : index
    %97 = arith.cmpi eq, %79, %81 : index
    %98 = arith.addi %68, %c1 : index
    %99 = arith.select %97, %98, %68 : index
    cf.br ^bb8(%96, %99, %93 : index, index, f32)
  ^bb14:  // pred: ^bb8
    %100 = llvm.getelementptr %12[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %63, %100 : f32, !llvm.ptr
    %101 = arith.addi %33, %c1 : index
    cf.br ^bb6(%101 : index)
  ^bb15:  // pred: ^bb6
    %102 = arith.addi %30, %c1 : index
    cf.br ^bb4(%102 : index)
  ^bb16:  // pred: ^bb4
    return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLLVMPass (convert-complex-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(240 : index) : i64
    %c16 = arith.constant 16 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c15 = arith.constant 15 : index
    %c0_i64 = arith.constant 0 : i64
    %c15_i64 = arith.constant 15 : i64
    %c16_i64 = arith.constant 16 : i64
    %c240_i64 = arith.constant 240 : i64
    %c1 = arith.constant 1 : index
    %c240 = arith.constant 240 : index
    %c0 = arith.constant 0 : index
    %3 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = llvm.mlir.null : !llvm.ptr
    %10 = llvm.getelementptr %9[240] : (!llvm.ptr) -> !llvm.ptr, f32
    %11 = llvm.ptrtoint %10 : !llvm.ptr to i64
    %12 = llvm.call @malloc(%11) : (i64) -> !llvm.ptr
    %13 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %14 = llvm.insertvalue %12, %13[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %12, %14[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %0, %15[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %2, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
    %25 = builtin.unrealized_conversion_cast %24 : index to i64
    %26 = arith.cmpi slt, %24, %c240 : index
    cf.cond_br %26, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %12[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %27 : f32, !llvm.ptr
    %28 = arith.addi %24, %c1 : index
    cf.br ^bb1(%28 : index)
  ^bb3:  // pred: ^bb1
    %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c15 : index
    cf.cond_br %32, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c16 : index
    cf.cond_br %35, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %36 = arith.muli %30, %c16 : index
    %37 = arith.addi %36, %33 : index
    %38 = builtin.unrealized_conversion_cast %37 : index to i64
    %39 = llvm.getelementptr %12[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %40 = llvm.load %39 : !llvm.ptr -> f32
    %41 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %43 = llvm.load %42 : !llvm.ptr -> i64
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    %45 = arith.addi %30, %c1 : index
    %46 = builtin.unrealized_conversion_cast %45 : index to i64
    %47 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %49 = llvm.load %48 : !llvm.ptr -> i64
    %50 = builtin.unrealized_conversion_cast %49 : i64 to index
    %51 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %53 = llvm.load %52 : !llvm.ptr -> i64
    %54 = builtin.unrealized_conversion_cast %53 : i64 to index
    %55 = arith.addi %33, %c1 : index
    %56 = builtin.unrealized_conversion_cast %55 : index to i64
    %57 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %59 = llvm.load %58 : !llvm.ptr -> i64
    %60 = builtin.unrealized_conversion_cast %59 : i64 to index
    cf.br ^bb8(%44, %54, %40 : index, index, f32)
  ^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
    %64 = arith.cmpi ult, %61, %50 : index
    %65 = arith.cmpi ult, %62, %60 : index
    %66 = arith.andi %64, %65 : i1
    cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
  ^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
    %70 = builtin.unrealized_conversion_cast %67 : index to i64
    %71 = builtin.unrealized_conversion_cast %68 : index to i64
    %72 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %74 = llvm.load %73 : !llvm.ptr -> i64
    %75 = builtin.unrealized_conversion_cast %74 : i64 to index
    %76 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %78 = llvm.load %77 : !llvm.ptr -> i64
    %79 = builtin.unrealized_conversion_cast %78 : i64 to index
    %80 = arith.cmpi ult, %79, %75 : index
    %81 = arith.select %80, %79, %75 : index
    %82 = arith.cmpi eq, %75, %81 : index
    %83 = arith.cmpi eq, %79, %81 : index
    %84 = arith.andi %82, %83 : i1
    cf.cond_br %84, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %85 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %87 = llvm.load %86 : !llvm.ptr -> f32
    %88 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %90 = llvm.load %89 : !llvm.ptr -> f32
    %91 = arith.mulf %87, %90 : f32
    %92 = arith.addf %69, %91 : f32
    cf.br ^bb12(%92 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%69 : f32)
  ^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %94 = arith.cmpi eq, %75, %81 : index
    %95 = arith.addi %67, %c1 : index
    %96 = arith.select %94, %95, %67 : index
    %97 = arith.cmpi eq, %79, %81 : index
    %98 = arith.addi %68, %c1 : index
    %99 = arith.select %97, %98, %68 : index
    cf.br ^bb8(%96, %99, %93 : index, index, f32)
  ^bb14:  // pred: ^bb8
    %100 = llvm.getelementptr %12[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %63, %100 : f32, !llvm.ptr
    %101 = arith.addi %33, %c1 : index
    cf.br ^bb6(%101 : index)
  ^bb15:  // pred: ^bb6
    %102 = arith.addi %30, %c1 : index
    cf.br ^bb4(%102 : index)
  ^bb16:  // pred: ^bb4
    return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  func.func @SpMSpMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf32>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(240 : index) : i64
    %c16 = arith.constant 16 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c15 = arith.constant 15 : index
    %c0_i64 = arith.constant 0 : i64
    %c15_i64 = arith.constant 15 : i64
    %c16_i64 = arith.constant 16 : i64
    %c240_i64 = arith.constant 240 : i64
    %c1 = arith.constant 1 : index
    %c240 = arith.constant 240 : index
    %c0 = arith.constant 0 : index
    %3 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg2 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = llvm.mlir.null : !llvm.ptr
    %10 = llvm.getelementptr %9[240] : (!llvm.ptr) -> !llvm.ptr, f32
    %11 = llvm.ptrtoint %10 : !llvm.ptr to i64
    %12 = llvm.call @malloc(%11) : (i64) -> !llvm.ptr
    %13 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %14 = llvm.insertvalue %12, %13[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %12, %14[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %0, %15[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %2, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = builtin.unrealized_conversion_cast %18 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %20 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %21 = llvm.insertvalue %c0_i64, %20[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %c15_i64, %21[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %c16_i64, %22[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%24: index):  // 2 preds: ^bb0, ^bb2
    %25 = builtin.unrealized_conversion_cast %24 : index to i64
    %26 = arith.cmpi slt, %24, %c240 : index
    cf.cond_br %26, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %12[%25] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %27 : f32, !llvm.ptr
    %28 = arith.addi %24, %c1 : index
    cf.br ^bb1(%28 : index)
  ^bb3:  // pred: ^bb1
    %29 = llvm.insertvalue %c240_i64, %23[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb4(%c0 : index)
  ^bb4(%30: index):  // 2 preds: ^bb3, ^bb15
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c15 : index
    cf.cond_br %32, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    cf.br ^bb6(%c0 : index)
  ^bb6(%33: index):  // 2 preds: ^bb5, ^bb14
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c16 : index
    cf.cond_br %35, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %36 = arith.muli %30, %c16 : index
    %37 = arith.addi %36, %33 : index
    %38 = builtin.unrealized_conversion_cast %37 : index to i64
    %39 = llvm.getelementptr %12[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %40 = llvm.load %39 : !llvm.ptr -> f32
    %41 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.getelementptr %41[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %43 = llvm.load %42 : !llvm.ptr -> i64
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    %45 = arith.addi %30, %c1 : index
    %46 = builtin.unrealized_conversion_cast %45 : index to i64
    %47 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.getelementptr %47[%46] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %49 = llvm.load %48 : !llvm.ptr -> i64
    %50 = builtin.unrealized_conversion_cast %49 : i64 to index
    %51 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.getelementptr %51[%34] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %53 = llvm.load %52 : !llvm.ptr -> i64
    %54 = builtin.unrealized_conversion_cast %53 : i64 to index
    %55 = arith.addi %33, %c1 : index
    %56 = builtin.unrealized_conversion_cast %55 : index to i64
    %57 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.getelementptr %57[%56] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %59 = llvm.load %58 : !llvm.ptr -> i64
    %60 = builtin.unrealized_conversion_cast %59 : i64 to index
    cf.br ^bb8(%44, %54, %40 : index, index, f32)
  ^bb8(%61: index, %62: index, %63: f32):  // 2 preds: ^bb7, ^bb13
    %64 = arith.cmpi ult, %61, %50 : index
    %65 = arith.cmpi ult, %62, %60 : index
    %66 = arith.andi %64, %65 : i1
    cf.cond_br %66, ^bb9(%61, %62, %63 : index, index, f32), ^bb14
  ^bb9(%67: index, %68: index, %69: f32):  // pred: ^bb8
    %70 = builtin.unrealized_conversion_cast %67 : index to i64
    %71 = builtin.unrealized_conversion_cast %68 : index to i64
    %72 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %73 = llvm.getelementptr %72[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %74 = llvm.load %73 : !llvm.ptr -> i64
    %75 = builtin.unrealized_conversion_cast %74 : i64 to index
    %76 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.getelementptr %76[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %78 = llvm.load %77 : !llvm.ptr -> i64
    %79 = builtin.unrealized_conversion_cast %78 : i64 to index
    %80 = arith.cmpi ult, %79, %75 : index
    %81 = arith.select %80, %79, %75 : index
    %82 = arith.cmpi eq, %75, %81 : index
    %83 = arith.cmpi eq, %79, %81 : index
    %84 = arith.andi %82, %83 : i1
    cf.cond_br %84, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %85 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %87 = llvm.load %86 : !llvm.ptr -> f32
    %88 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.getelementptr %88[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %90 = llvm.load %89 : !llvm.ptr -> f32
    %91 = arith.mulf %87, %90 : f32
    %92 = arith.addf %69, %91 : f32
    cf.br ^bb12(%92 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%69 : f32)
  ^bb12(%93: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %94 = arith.cmpi eq, %75, %81 : index
    %95 = arith.addi %67, %c1 : index
    %96 = arith.select %94, %95, %67 : index
    %97 = arith.cmpi eq, %79, %81 : index
    %98 = arith.addi %68, %c1 : index
    %99 = arith.select %97, %98, %68 : index
    cf.br ^bb8(%96, %99, %93 : index, index, f32)
  ^bb14:  // pred: ^bb8
    %100 = llvm.getelementptr %12[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %63, %100 : f32, !llvm.ptr
    %101 = arith.addi %33, %c1 : index
    cf.br ^bb6(%101 : index)
  ^bb15:  // pred: ^bb6
    %102 = arith.addi %30, %c1 : index
    cf.br ^bb4(%102 : index)
  ^bb16:  // pred: ^bb4
    return %19, %29 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertFuncToLLVMPass (convert-func-to-llvm) //----- //
module attributes {llvm.data_layout = ""} {
  llvm.func @malloc(i64) -> !llvm.ptr
  llvm.func @SpMSpMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg16: !llvm.ptr, %arg17: !llvm.ptr, %arg18: i64, %arg19: i64, %arg20: i64, %arg21: !llvm.ptr, %arg22: !llvm.ptr, %arg23: i64, %arg24: i64, %arg25: i64, %arg26: !llvm.ptr, %arg27: !llvm.ptr, %arg28: i64, %arg29: i64, %arg30: i64, %arg31: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = builtin.unrealized_conversion_cast %5 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %7 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.insertvalue %arg5, %7[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg7, %9[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg8, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.insertvalue %arg9, %11[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %14 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %15 = llvm.insertvalue %arg10, %14[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg11, %15[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg12, %16[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %arg13, %17[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %arg14, %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %21 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %22 = llvm.insertvalue %arg16, %21[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg17, %22[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %arg18, %23[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %arg19, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg20, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = builtin.unrealized_conversion_cast %26 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %28 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %arg21, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %arg22, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %arg23, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg24, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg25, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %36 = llvm.insertvalue %arg26, %35[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %arg27, %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg28, %37[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.insertvalue %arg29, %38[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.insertvalue %arg30, %39[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = builtin.unrealized_conversion_cast %40 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %42 = llvm.mlir.constant(0 : index) : i64
    %43 = llvm.mlir.constant(1 : index) : i64
    %44 = llvm.mlir.constant(240 : index) : i64
    %45 = llvm.mlir.constant(16 : index) : i64
    %46 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %47 = llvm.mlir.constant(15 : index) : i64
    %48 = llvm.mlir.constant(0 : i64) : i64
    %49 = llvm.mlir.constant(15 : i64) : i64
    %50 = llvm.mlir.constant(16 : i64) : i64
    %51 = llvm.mlir.constant(240 : i64) : i64
    %52 = llvm.mlir.constant(1 : index) : i64
    %53 = llvm.mlir.constant(240 : index) : i64
    %54 = llvm.mlir.constant(0 : index) : i64
    %55 = builtin.unrealized_conversion_cast %6 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %56 = builtin.unrealized_conversion_cast %27 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %57 = builtin.unrealized_conversion_cast %13 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %58 = builtin.unrealized_conversion_cast %34 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %59 = builtin.unrealized_conversion_cast %20 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %60 = builtin.unrealized_conversion_cast %41 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %61 = llvm.mlir.null : !llvm.ptr
    %62 = llvm.getelementptr %61[240] : (!llvm.ptr) -> !llvm.ptr, f32
    %63 = llvm.ptrtoint %62 : !llvm.ptr to i64
    %64 = llvm.call @malloc(%63) : (i64) -> !llvm.ptr
    %65 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %66 = llvm.insertvalue %64, %65[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.insertvalue %64, %66[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %68 = llvm.insertvalue %42, %67[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %69 = llvm.insertvalue %44, %68[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %70 = llvm.insertvalue %43, %69[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %71 = builtin.unrealized_conversion_cast %70 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %72 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %73 = llvm.insertvalue %48, %72[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %74 = llvm.insertvalue %49, %73[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %75 = llvm.insertvalue %50, %74[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%54 : i64)
  ^bb1(%76: i64):  // 2 preds: ^bb0, ^bb2
    %77 = builtin.unrealized_conversion_cast %76 : i64 to index
    %78 = builtin.unrealized_conversion_cast %77 : index to i64
    %79 = llvm.icmp "slt" %76, %53 : i64
    llvm.cond_br %79, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %80 = llvm.getelementptr %64[%78] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %46, %80 : f32, !llvm.ptr
    %81 = llvm.add %76, %52  : i64
    llvm.br ^bb1(%81 : i64)
  ^bb3:  // pred: ^bb1
    %82 = llvm.insertvalue %51, %75[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    llvm.br ^bb4(%54 : i64)
  ^bb4(%83: i64):  // 2 preds: ^bb3, ^bb15
    %84 = builtin.unrealized_conversion_cast %83 : i64 to index
    %85 = builtin.unrealized_conversion_cast %84 : index to i64
    %86 = llvm.icmp "slt" %83, %47 : i64
    llvm.cond_br %86, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    llvm.br ^bb6(%54 : i64)
  ^bb6(%87: i64):  // 2 preds: ^bb5, ^bb14
    %88 = builtin.unrealized_conversion_cast %87 : i64 to index
    %89 = builtin.unrealized_conversion_cast %88 : index to i64
    %90 = llvm.icmp "slt" %87, %45 : i64
    llvm.cond_br %90, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %91 = llvm.mul %83, %45  : i64
    %92 = llvm.add %91, %87  : i64
    %93 = builtin.unrealized_conversion_cast %92 : i64 to index
    %94 = builtin.unrealized_conversion_cast %93 : index to i64
    %95 = llvm.getelementptr %64[%94] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %96 = llvm.load %95 : !llvm.ptr -> f32
    %97 = llvm.extractvalue %55[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %98 = llvm.getelementptr %97[%85] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %99 = llvm.load %98 : !llvm.ptr -> i64
    %100 = builtin.unrealized_conversion_cast %99 : i64 to index
    %101 = llvm.add %83, %52  : i64
    %102 = builtin.unrealized_conversion_cast %101 : i64 to index
    %103 = builtin.unrealized_conversion_cast %102 : index to i64
    %104 = llvm.extractvalue %55[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %105 = llvm.getelementptr %104[%103] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %106 = llvm.load %105 : !llvm.ptr -> i64
    %107 = builtin.unrealized_conversion_cast %106 : i64 to index
    %108 = llvm.extractvalue %56[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %109 = llvm.getelementptr %108[%89] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %110 = llvm.load %109 : !llvm.ptr -> i64
    %111 = builtin.unrealized_conversion_cast %110 : i64 to index
    %112 = llvm.add %87, %52  : i64
    %113 = builtin.unrealized_conversion_cast %112 : i64 to index
    %114 = builtin.unrealized_conversion_cast %113 : index to i64
    %115 = llvm.extractvalue %56[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %116 = llvm.getelementptr %115[%114] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %117 = llvm.load %116 : !llvm.ptr -> i64
    %118 = builtin.unrealized_conversion_cast %117 : i64 to index
    llvm.br ^bb8(%99, %110, %96 : i64, i64, f32)
  ^bb8(%119: i64, %120: i64, %121: f32):  // 2 preds: ^bb7, ^bb13
    %122 = llvm.icmp "ult" %119, %106 : i64
    %123 = llvm.icmp "ult" %120, %117 : i64
    %124 = llvm.and %122, %123  : i1
    llvm.cond_br %124, ^bb9(%119, %120, %121 : i64, i64, f32), ^bb14
  ^bb9(%125: i64, %126: i64, %127: f32):  // pred: ^bb8
    %128 = builtin.unrealized_conversion_cast %126 : i64 to index
    %129 = builtin.unrealized_conversion_cast %125 : i64 to index
    %130 = builtin.unrealized_conversion_cast %129 : index to i64
    %131 = builtin.unrealized_conversion_cast %128 : index to i64
    %132 = llvm.extractvalue %57[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %133 = llvm.getelementptr %132[%130] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %134 = llvm.load %133 : !llvm.ptr -> i64
    %135 = builtin.unrealized_conversion_cast %134 : i64 to index
    %136 = llvm.extractvalue %58[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %137 = llvm.getelementptr %136[%131] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %138 = llvm.load %137 : !llvm.ptr -> i64
    %139 = builtin.unrealized_conversion_cast %138 : i64 to index
    %140 = llvm.icmp "ult" %138, %134 : i64
    %141 = llvm.select %140, %138, %134 : i1, i64
    %142 = llvm.icmp "eq" %134, %141 : i64
    %143 = llvm.icmp "eq" %138, %141 : i64
    %144 = llvm.and %142, %143  : i1
    llvm.cond_br %144, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %145 = llvm.extractvalue %59[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %146 = llvm.getelementptr %145[%130] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %147 = llvm.load %146 : !llvm.ptr -> f32
    %148 = llvm.extractvalue %60[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %149 = llvm.getelementptr %148[%131] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %150 = llvm.load %149 : !llvm.ptr -> f32
    %151 = llvm.fmul %147, %150  : f32
    %152 = llvm.fadd %127, %151  : f32
    llvm.br ^bb12(%152 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%127 : f32)
  ^bb12(%153: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %154 = llvm.icmp "eq" %134, %141 : i64
    %155 = llvm.add %125, %52  : i64
    %156 = llvm.select %154, %155, %125 : i1, i64
    %157 = llvm.icmp "eq" %138, %141 : i64
    %158 = llvm.add %126, %52  : i64
    %159 = llvm.select %157, %158, %126 : i1, i64
    llvm.br ^bb8(%156, %159, %153 : i64, i64, f32)
  ^bb14:  // pred: ^bb8
    %160 = llvm.getelementptr %64[%94] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %121, %160 : f32, !llvm.ptr
    %161 = llvm.add %87, %52  : i64
    llvm.br ^bb6(%161 : i64)
  ^bb15:  // pred: ^bb6
    %162 = llvm.add %83, %52  : i64
    llvm.br ^bb4(%162 : i64)
  ^bb16:  // pred: ^bb4
    %163 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    %164 = llvm.insertvalue %70, %163[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    %165 = llvm.insertvalue %82, %164[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    llvm.return %165 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpMSpMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.call @SpMSpMMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %arg4, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %arg8) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    llvm.store %36, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module attributes {llvm.data_layout = ""} {
  llvm.func @malloc(i64) -> !llvm.ptr
  llvm.func @SpMSpMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg16: !llvm.ptr, %arg17: !llvm.ptr, %arg18: i64, %arg19: i64, %arg20: i64, %arg21: !llvm.ptr, %arg22: !llvm.ptr, %arg23: i64, %arg24: i64, %arg25: i64, %arg26: !llvm.ptr, %arg27: !llvm.ptr, %arg28: i64, %arg29: i64, %arg30: i64, %arg31: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.insertvalue %arg5, %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.insertvalue %arg6, %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg7, %8[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg8, %9[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg9, %10[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.insertvalue %arg10, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %arg11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %arg12, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg13, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg14, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %arg16, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %arg17, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %arg18, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %arg19, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg20, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.insertvalue %arg21, %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg22, %25[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %arg23, %26[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %arg24, %27[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %arg25, %28[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.insertvalue %arg26, %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg27, %31[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg28, %32[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %arg29, %33[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.insertvalue %arg30, %34[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.mlir.constant(0 : index) : i64
    %37 = llvm.mlir.constant(1 : index) : i64
    %38 = llvm.mlir.constant(240 : index) : i64
    %39 = llvm.mlir.constant(16 : index) : i64
    %40 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %41 = llvm.mlir.constant(15 : index) : i64
    %42 = llvm.mlir.constant(0 : i64) : i64
    %43 = llvm.mlir.constant(15 : i64) : i64
    %44 = llvm.mlir.constant(16 : i64) : i64
    %45 = llvm.mlir.constant(240 : i64) : i64
    %46 = llvm.mlir.constant(1 : index) : i64
    %47 = llvm.mlir.constant(240 : index) : i64
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.mlir.null : !llvm.ptr
    %50 = llvm.getelementptr %49[240] : (!llvm.ptr) -> !llvm.ptr, f32
    %51 = llvm.ptrtoint %50 : !llvm.ptr to i64
    %52 = llvm.call @malloc(%51) : (i64) -> !llvm.ptr
    %53 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %54 = llvm.insertvalue %52, %53[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %55 = llvm.insertvalue %52, %54[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %56 = llvm.insertvalue %36, %55[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %57 = llvm.insertvalue %38, %56[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.insertvalue %37, %57[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %59 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %60 = llvm.insertvalue %42, %59[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %61 = llvm.insertvalue %43, %60[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %62 = llvm.insertvalue %44, %61[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%48 : i64)
  ^bb1(%63: i64):  // 2 preds: ^bb0, ^bb2
    %64 = llvm.icmp "slt" %63, %47 : i64
    llvm.cond_br %64, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %65 = llvm.getelementptr %52[%63] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %40, %65 : f32, !llvm.ptr
    %66 = llvm.add %63, %46  : i64
    llvm.br ^bb1(%66 : i64)
  ^bb3:  // pred: ^bb1
    %67 = llvm.insertvalue %45, %62[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    llvm.br ^bb4(%48 : i64)
  ^bb4(%68: i64):  // 2 preds: ^bb3, ^bb15
    %69 = llvm.icmp "slt" %68, %41 : i64
    llvm.cond_br %69, ^bb5, ^bb16
  ^bb5:  // pred: ^bb4
    llvm.br ^bb6(%48 : i64)
  ^bb6(%70: i64):  // 2 preds: ^bb5, ^bb14
    %71 = llvm.icmp "slt" %70, %39 : i64
    llvm.cond_br %71, ^bb7, ^bb15
  ^bb7:  // pred: ^bb6
    %72 = llvm.mul %68, %39  : i64
    %73 = llvm.add %72, %70  : i64
    %74 = llvm.getelementptr %52[%73] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %75 = llvm.load %74 : !llvm.ptr -> f32
    %76 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.getelementptr %76[%68] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %78 = llvm.load %77 : !llvm.ptr -> i64
    %79 = llvm.add %68, %46  : i64
    %80 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %81 = llvm.getelementptr %80[%79] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %82 = llvm.load %81 : !llvm.ptr -> i64
    %83 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %84 = llvm.getelementptr %83[%70] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %85 = llvm.load %84 : !llvm.ptr -> i64
    %86 = llvm.add %70, %46  : i64
    %87 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %88 = llvm.getelementptr %87[%86] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %89 = llvm.load %88 : !llvm.ptr -> i64
    llvm.br ^bb8(%78, %85, %75 : i64, i64, f32)
  ^bb8(%90: i64, %91: i64, %92: f32):  // 2 preds: ^bb7, ^bb13
    %93 = llvm.icmp "ult" %90, %82 : i64
    %94 = llvm.icmp "ult" %91, %89 : i64
    %95 = llvm.and %93, %94  : i1
    llvm.cond_br %95, ^bb9(%90, %91, %92 : i64, i64, f32), ^bb14
  ^bb9(%96: i64, %97: i64, %98: f32):  // pred: ^bb8
    %99 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %100 = llvm.getelementptr %99[%96] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %101 = llvm.load %100 : !llvm.ptr -> i64
    %102 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %103 = llvm.getelementptr %102[%97] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %104 = llvm.load %103 : !llvm.ptr -> i64
    %105 = llvm.icmp "ult" %104, %101 : i64
    %106 = llvm.select %105, %104, %101 : i1, i64
    %107 = llvm.icmp "eq" %101, %106 : i64
    %108 = llvm.icmp "eq" %104, %106 : i64
    %109 = llvm.and %107, %108  : i1
    llvm.cond_br %109, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %110 = llvm.extractvalue %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %111 = llvm.getelementptr %110[%96] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %112 = llvm.load %111 : !llvm.ptr -> f32
    %113 = llvm.extractvalue %35[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %114 = llvm.getelementptr %113[%97] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %115 = llvm.load %114 : !llvm.ptr -> f32
    %116 = llvm.fmul %112, %115  : f32
    %117 = llvm.fadd %98, %116  : f32
    llvm.br ^bb12(%117 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%98 : f32)
  ^bb12(%118: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %119 = llvm.icmp "eq" %101, %106 : i64
    %120 = llvm.add %96, %46  : i64
    %121 = llvm.select %119, %120, %96 : i1, i64
    %122 = llvm.icmp "eq" %104, %106 : i64
    %123 = llvm.add %97, %46  : i64
    %124 = llvm.select %122, %123, %97 : i1, i64
    llvm.br ^bb8(%121, %124, %118 : i64, i64, f32)
  ^bb14:  // pred: ^bb8
    %125 = llvm.getelementptr %52[%73] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %92, %125 : f32, !llvm.ptr
    %126 = llvm.add %70, %46  : i64
    llvm.br ^bb6(%126 : i64)
  ^bb15:  // pred: ^bb6
    %127 = llvm.add %68, %46  : i64
    llvm.br ^bb4(%127 : i64)
  ^bb16:  // pred: ^bb4
    %128 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    %129 = llvm.insertvalue %58, %128[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    %130 = llvm.insertvalue %67, %129[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    llvm.return %130 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpMSpMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<2 x i64>, array<3 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.call @SpMSpMMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %arg4, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %arg8) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    llvm.store %36, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


