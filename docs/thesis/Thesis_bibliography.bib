%% BibTeX bibliography
% Encoding: UTF-8

%%% This paper presented the first accelerator architecture targeting GNNs
@INPROCEEDINGS{9218751,
    author = {Auten, Adam and Tomei, Matthew and Kumar, Rakesh},
    booktitle = {2020 57th ACM/IEEE Design Automation Conference (DAC)},
    title = {Hardware Acceleration of Graph Neural Networks},
    year = {2020},
    volume = {},
    number = {},
    pages = {1-6},
    doi = {10.1109/DAC18072.2020.9218751}
}

%%% paper that introduced Graph Isomorphism Network (GIN)
@misc{xu2019powerful,
    title = {How Powerful are Graph Neural Networks?},
    author = {Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
    year = {2019},
    eprint = {1810.00826},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

%%% paper that presents SODA toolchain and Bambu, used for this Master Thesis
@ARTICLE{9786533,
    author = {Agostini, Nicolas Bohm and Curzel, Serena and Zhang, Jeff Jun and Limaye, Ankur and Tan, Cheng and Amatya, Vinay and Minutoli, Marco and Castellana, Vito Giovanni and Manzano, Joseph and Brooks, David and Wei, Gu-Yeon and Tumeo, Antonino},
    journal = {IEEE Micro},
    title = {Bridging Python to Silicon: The SODA Toolchain},
    year = {2022},
    volume = {42},
    number = {5},
    pages = {78-88},
    doi = {10.1109/MM.2022.3178580}
}

%%% paper that introduces DeepBurningGL, a framework that can easily generate application-specific GNN accelerators from the software-described models.
@INPROCEEDINGS{9256539,
    author = {Liang, Shengwen and Liu, Cheng and Wang, Ying and Li, Huawei and Li, Xiaowei},
    booktitle = {2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD)},
    title = {DeepBurning-GL: an Automated Framework for Generating Graph Neural Network Accelerators},
    year = {2020},
    volume = {},
    number = {},
    pages = {1-9},
    doi = {}
}

%%% paper that presents GenGNN, a generic GNN acceleration framework using High-Level Synthesis (HLS)
@article{DBLP:journals/corr/abs-2201-08475,
    author = {Stefan Abi{-}Karam and
 Yuqi He and
 Rishov Sarkar and
 Lakshmi Sathidevi and
 Zihang Qiao and
 Cong Hao},
    title = {GenGNN: {A} Generic {FPGA} Framework for Graph Neural Network Acceleration},
    journal = {CoRR},
    volume = {abs/2201.08475},
    year = {2022},
    url = {https://arxiv.org/abs/2201.08475},
    eprinttype = {arXiv},
    eprint = {2201.08475},
    timestamp = {Tue, 01 Feb 2022 14:59:01 +0100},
    biburl = {https://dblp.org/rec/journals/corr/abs-2201-08475.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that introduced GraphLily, a graph linear algebra overlay, to accelerate graph processing on HBM-equipped FPGAs.
@INPROCEEDINGS{9643582,
    author = {Hu, Yuwei and Du, Yixiao and Ustun, Ecenur and Zhang, Zhiru},
    booktitle = {2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)},
    title = {GraphLily: Accelerating Graph Linear Algebra on HBM-Equipped FPGAs},
    year = {2021},
    volume = {},
    number = {},
    pages = {1-9},
    doi = {10.1109/ICCAD51958.2021.9643582}
}

%%% paper that introduced GRIP, a graph neural network accelera- tor architecture designed for low-latency inference.
@article{DBLP:journals/corr/abs-2007-13828,
    author = {Kevin Kiningham and
 Christopher R{\'{e}} and
 Philip Alexander Levis},
    title = {{GRIP:} {A} Graph Neural Network Accelerator Architecture},
    journal = {CoRR},
    volume = {abs/2007.13828},
    year = {2020},
    url = {https://arxiv.org/abs/2007.13828},
    eprinttype = {arXiv},
    eprint = {2007.13828},
    timestamp = {Mon, 30 Aug 2021 16:42:54 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-2007-13828.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that introduced Graph Convolutional Network (GCN)
@article{DBLP:journals/corr/KipfW16,
    author = {Thomas N. Kipf and
 Max Welling},
    title = {Semi-Supervised Classification with Graph Convolutional Networks},
    journal = {CoRR},
    volume = {abs/1609.02907},
    year = {2016},
    url = {http://arxiv.org/abs/1609.02907},
    eprinttype = {arXiv},
    eprint = {1609.02907},
    timestamp = {Mon, 13 Aug 2018 16:48:31 +0200},
    biburl = {https://dblp.org/rec/journals/corr/KipfW16.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that introduces HyGCN, a GCN accelerator using hybrid architecture to efficiently perform GCNs
@article{DBLP:journals/corr/abs-2001-02514,
    author = {Mingyu Yan and
 Lei Deng and
 Xing Hu and
 Ling Liang and
 Yujing Feng and
 Xiaochun Ye and
 Zhimin Zhang and
 Dongrui Fan and
 Yuan Xie},
    title = {HyGCN: {A} {GCN} Accelerator with Hybrid Architecture},
    journal = {CoRR},
    volume = {abs/2001.02514},
    year = {2020},
    url = {http://arxiv.org/abs/2001.02514},
    eprinttype = {arXiv},
    eprint = {2001.02514},
    timestamp = {Fri, 17 Jun 2022 20:50:39 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-2001-02514.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that describes OGB, it explains what OGB is and what it can be used for
@inproceedings{NEURIPS2020_fb60d411,
    author = {Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
    pages = {22118--22133},
    publisher = {Curran Associates, Inc.},
    title = {Open Graph Benchmark: Datasets for Machine Learning on Graphs},
    url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/fb60d411a5c5b72b2e7d3527cfc84fd0-Paper.pdf},
    volume = {33},
    year = {2020}
}

%%% paper that introduces EnGN, a specialized accelerator architecture which aims to
%%% enable high-throughput and energy-efficient processing of large-scale GNNs (it improved HyGCN)
@article{DBLP:journals/corr/abs-1909-00155,
    author = {Lei He},
    title = {EnGN: {A} High-Throughput and Energy-Efficient Accelerator for Large
 Graph Neural Networks},
    journal = {CoRR},
    volume = {abs/1909.00155},
    year = {2019},
    url = {http://arxiv.org/abs/1909.00155},
    eprinttype = {arXiv},
    eprint = {1909.00155},
    timestamp = {Mon, 16 Sep 2019 17:27:14 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1909-00155.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that describes how SparseTensors have been implemented in MLIR, explaining the important notation
@article{Bik_2022,
	doi = {10.1145/3544559},
	url = {https://doi.org/10.1145%2F3544559},
	year = 2022,
	month = {sep},
	publisher = {Association for Computing Machinery ({ACM})},
	volume = {19},
	number = {4},
	pages = {1--25},
	author = {Aart Bik and Penporn Koanantakool and Tatiana Shpeisman and Nicolas Vasilache and Bixia Zheng and Fredrik Kjolstad},
	title = {Compiler Support for Sparse Tensor Computations in {MLIR}},
	journal = {{ACM} Transactions on Architecture and Code Optimization}
}

%%% online paper that describe really well graph neural networks and how they work
@article{sanchez-lengeling2021a,
  author = {Sanchez-Lengeling, Benjamin and Reif, Emily and Pearce, Adam and Wiltschko, Alexander B.},
  title = {A Gentle Introduction to Graph Neural Networks},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2021/gnn-intro},
  doi = {10.23915/distill.00033}
}

%%% paper that describes how to improve the performance of a matmul for cpu using MLIR
@article{DBLP:journals/corr/abs-2003-00532,
  author       = {Uday Bondhugula},
  title        = {High Performance Code Generation in {MLIR:} An Early Case Study with
                  {GEMM}},
  journal      = {CoRR},
  volume       = {abs/2003.00532},
  year         = {2020},
  url          = {https://arxiv.org/abs/2003.00532},
  eprinttype    = {arXiv},
  eprint       = {2003.00532},
  timestamp    = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2003-00532.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% online paper that describes,  step-by-step, how to optimize a matmul kernel
@online{opt_cuda_matmul,
    author = {Simon BÃ¶hm},
    title = {How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog},
    year = {2022},
    date = {29-June-2023},
    url = {https://siboehm.com/articles/22/CUDA-MMM}
}

%%% paper that summarise graph neural networks, explaining the different categories and their uses
@article{DBLP:journals/corr/abs-1901-00596,
  author       = {Zonghan Wu and
                  Shirui Pan and
                  Fengwen Chen and
                  Guodong Long and
                  Chengqi Zhang and
                  Philip S. Yu},
  title        = {A Comprehensive Survey on Graph Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1901.00596},
  year         = {2019},
  url          = {http://arxiv.org/abs/1901.00596},
  eprinttype    = {arXiv},
  eprint       = {1901.00596},
  timestamp    = {Thu, 31 Jan 2019 13:52:49 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1901-00596.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



%%% paper that introduced PyTorch library
@article{DBLP:journals/corr/abs-1912-01703,
  author       = {Adam Paszke and
                  Sam Gross and
                  Francisco Massa and
                  Adam Lerer and
                  James Bradbury and
                  Gregory Chanan and
                  Trevor Killeen and
                  Zeming Lin and
                  Natalia Gimelshein and
                  Luca Antiga and
                  Alban Desmaison and
                  Andreas K{\"{o}}pf and
                  Edward Z. Yang and
                  Zach DeVito and
                  Martin Raison and
                  Alykhan Tejani and
                  Sasank Chilamkurthy and
                  Benoit Steiner and
                  Lu Fang and
                  Junjie Bai and
                  Soumith Chintala},
  title        = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  journal      = {CoRR},
  volume       = {abs/1912.01703},
  year         = {2019},
  url          = {http://arxiv.org/abs/1912.01703},
  eprinttype    = {arXiv},
  eprint       = {1912.01703},
  timestamp    = {Tue, 02 Nov 2021 15:18:32 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1912-01703.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that introduced PyTorch Geometric library
@article{DBLP:journals/corr/abs-1903-02428,
  author       = {Matthias Fey and
                  Jan Eric Lenssen},
  title        = {Fast Graph Representation Learning with PyTorch Geometric},
  journal      = {CoRR},
  volume       = {abs/1903.02428},
  year         = {2019},
  url          = {http://arxiv.org/abs/1903.02428},
  eprinttype    = {arXiv},
  eprint       = {1903.02428},
  timestamp    = {Sun, 31 Mar 2019 19:01:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1903-02428.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% another paper that summarise GNNs
@article{DBLP:journals/corr/abs-1812-08434,
  author       = {Jie Zhou and
                  Ganqu Cui and
                  Zhengyan Zhang and
                  Cheng Yang and
                  Zhiyuan Liu and
                  Maosong Sun},
  title        = {Graph Neural Networks: {A} Review of Methods and Applications},
  journal      = {CoRR},
  volume       = {abs/1812.08434},
  year         = {2018},
  url          = {http://arxiv.org/abs/1812.08434},
  eprinttype    = {arXiv},
  eprint       = {1812.08434},
  timestamp    = {Tue, 01 Dec 2020 13:54:50 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1812-08434.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that introduces MLIR
@INPROCEEDINGS{9370308,
  author={Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  booktitle={2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  title={MLIR: Scaling Compiler Infrastructure for Domain Specific Computation},
  year={2021},
  volume={},
  number={},
  pages={2-14},
  doi={10.1109/CGO51591.2021.9370308}
}

%%% paper that introduced Bambu
@INPROCEEDINGS{9586110,
  author={Ferrandi, Fabrizio and Castellana, Vito Giovanni and Curzel, Serena and Fezzardi, Pietro and Fiorito, Michele and Lattuada, Marco and Minutoli, Marco and Pilato, Christian and Tumeo, Antonino},
  booktitle={2021 58th ACM/IEEE Design Automation Conference (DAC)},
  title={Invited: Bambu: an Open-Source Research Framework for the High-Level Synthesis of Complex Applications},
  year={2021},
  volume={},
  number={},
  pages={1327-1330},
  doi={10.1109/DAC18074.2021.9586110}
}

%%% reference to torch-mlir GitHub page
@online{torch_mlir,
    author = {Torch-MLIR team, nod.ai team and other contributors},
    title = {Torch-MLIR: MLIR based compiler toolkit for PyTorch programs},
    year = {2021},
    date = {06-July-2023},
    url = {https://github.com/llvm/torch-mlir},
}

%%% GitHub repository of the GIN model from OGB
@online{ogb_gnn_models,
    author = {Open Graph Benchmark team and other contributors},
    title = {GNN models from Open Graph Benchmark},
    year = {2020},
    date = {06-July-2023},
    url = {https://github.com/snap-stanford/ogb/tree/master/examples/graphproppred/mol},
}

%%% GitHub repository of the GCN model
@online{pygcn,
    author = {Thomas N. Kipf, Max Welling and other contributors},
    title = {GCN model in PyTorch},
    date = {06-July-2023},
    year = {2017},
    url = {https://github.com/tkipf/pygcn},
}

%%% paper that introduces a Convolutional Neural Network that generalizes standard molecular feature
@article{DBLP:journals/corr/DuvenaudMAGHAA15,
  author       = {David Duvenaud and
                  Dougal Maclaurin and
                  Jorge Aguilera{-}Iparraguirre and
                  Rafael G{\'{o}}mez{-}Bombarelli and
                  Timothy Hirzel and
                  Al{\'{a}}n Aspuru{-}Guzik and
                  Ryan P. Adams},
  title        = {Convolutional Networks on Graphs for Learning Molecular Fingerprints},
  journal      = {CoRR},
  volume       = {abs/1509.09292},
  year         = {2015},
  url          = {http://arxiv.org/abs/1509.09292},
  eprinttype    = {arXiv},
  eprint       = {1509.09292},
  timestamp    = {Mon, 22 Jul 2019 14:09:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DuvenaudMAGHAA15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% nice article that explains GNNs
@article{daigavane2021understanding,
  author = {Daigavane, Ameya and Ravindran, Balaraman and Aggarwal, Gaurav},
  title = {Understanding Convolutions on Graphs},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2021/understanding-gnns},
  doi = {10.23915/distill.00032}
}

%%% paper that summarise GNNs and their accelerators
@article{DBLP:journals/corr/abs-2010-00130,
  author       = {Sergi Abadal and
                  Akshay Jain and
                  Robert Guirado and
                  Jorge L{\'{o}}pez{-}Alonso and
                  Eduard Alarc{\'{o}}n},
  title        = {Computing Graph Neural Networks: {A} Survey from Algorithms to Accelerators},
  journal      = {CoRR},
  volume       = {abs/2010.00130},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.00130},
  eprinttype    = {arXiv},
  eprint       = {2010.00130},
  timestamp    = {Thu, 14 Oct 2021 09:13:50 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-00130.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% this paper express the fact that more than 5 layers for a GNN can lead to overfitting
@article{DBLP:journals/corr/abs-1801-07606,
  author       = {Qimai Li and
                  Zhichao Han and
                  Xiao{-}Ming Wu},
  title        = {Deeper Insights into Graph Convolutional Networks for Semi-Supervised
                  Learning},
  journal      = {CoRR},
  volume       = {abs/1801.07606},
  year         = {2018},
  url          = {http://arxiv.org/abs/1801.07606},
  eprinttype    = {arXiv},
  eprint       = {1801.07606},
  timestamp    = {Mon, 10 Jan 2022 15:47:05 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1801-07606.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that talk about graph pooling
@article{DBLP:journals/corr/abs-1806-08804,
  author       = {Rex Ying and
                  Jiaxuan You and
                  Christopher Morris and
                  Xiang Ren and
                  William L. Hamilton and
                  Jure Leskovec},
  title        = {Hierarchical Graph Representation Learning with Differentiable Pooling},
  journal      = {CoRR},
  volume       = {abs/1806.08804},
  year         = {2018},
  url          = {http://arxiv.org/abs/1806.08804},
  eprinttype    = {arXiv},
  eprint       = {1806.08804},
  timestamp    = {Wed, 11 Aug 2021 19:23:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1806-08804.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% paper which talks about layer sampling
@article{DBLP:journals/corr/HamiltonYL17,
  author       = {William L. Hamilton and
                  Rex Ying and
                  Jure Leskovec},
  title        = {Inductive Representation Learning on Large Graphs},
  journal      = {CoRR},
  volume       = {abs/1706.02216},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.02216},
  eprinttype    = {arXiv},
  eprint       = {1706.02216},
  timestamp    = {Mon, 13 Aug 2018 16:46:12 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HamiltonYL17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that presented Deep Graph Library (DGL)
@article{DBLP:journals/corr/abs-1909-01315,
  author       = {Minjie Wang and
                  Lingfan Yu and
                  Da Zheng and
                  Quan Gan and
                  Yu Gai and
                  Zihao Ye and
                  Mufei Li and
                  Jinjing Zhou and
                  Qi Huang and
                  Chao Ma and
                  Ziyue Huang and
                  Qipeng Guo and
                  Hao Zhang and
                  Haibin Lin and
                  Junbo Zhao and
                  Jinyang Li and
                  Alexander J. Smola and
                  Zheng Zhang},
  title        = {Deep Graph Library: Towards Efficient and Scalable Deep Learning on
                  Graphs},
  journal      = {CoRR},
  volume       = {abs/1909.01315},
  year         = {2019},
  url          = {http://arxiv.org/abs/1909.01315},
  eprinttype    = {arXiv},
  eprint       = {1909.01315},
  timestamp    = {Thu, 25 Nov 2021 21:01:37 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1909-01315.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%% paper which introduced AWB_GCN accelerator
@article{DBLP:journals/corr/abs-1908-10834,
  author       = {Tong Geng and
                  Ang Li and
                  Tianqi Wang and
                  Chunshu Wu and
                  Yanfei Li and
                  Antonino Tumeo and
                  Martin C. Herbordt},
  title        = {{AWB-GCN:} Hardware Acceleration of Graph-Convolution-Network through
                  Runtime Workload Rebalancing},
  journal      = {CoRR},
  volume       = {abs/1908.10834},
  year         = {2019},
  url          = {http://arxiv.org/abs/1908.10834},
  eprinttype    = {arXiv},
  eprint       = {1908.10834},
  timestamp    = {Thu, 01 Dec 2022 10:26:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1908-10834.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%% paper that introduced the accelerator of Zhang et. al (software-hardware accelerator)
@INPROCEEDINGS{9153263,
  author={Zhang, Bingyi and Zeng, Hanqing and Prasanna, Viktor},
  booktitle={2020 IEEE 31st International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
  title={Hardware Acceleration of Large Scale GCN Inference},
  year={2020},
  volume={},
  number={},
  pages={61-68},
  doi={10.1109/ASAP49362.2020.00019}}

%% paper that introduced DGNN-Booster
@misc{chen2023dgnnbooster,
      title={DGNN-Booster: A Generic FPGA Accelerator Framework For Dynamic Graph Neural Network Inference},
      author={Hanqiu Chen and Cong Hao},
      year={2023},
      eprint={2304.06831},
      archivePrefix={arXiv},
      primaryClass={cs.AR}
}

%% paper that introduced GReTA
@inproceedings{greta-recoml20,
  author    = "Kevin Kiningham and Philip Levis and Christopher Re",
  title     = "{GReTA: Hardware Optimized Graph Processing for GNNs}",
  booktitle = "{Proceedings of the Workshop on Resource-Constrained Machine Learning (ReCoML 2020)}",
  year      = {2020},
  month     = {March}
}

%% paper that introduces BoostGCN
@INPROCEEDINGS{9444065,
  author={Zhang, Bingyi and Kannan, Rajgopal and Prasanna, Viktor},
  booktitle={2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
  title={BoostGCN: A Framework for Optimizing GCN Inference on FPGA},
  year={2021},
  volume={},
  number={},
  pages={29-39},
  doi={10.1109/FCCM51124.2021.00012}}

%% paper that introduced virtual nodes
@article{DBLP:journals/corr/GilmerSRVD17,
  author       = {Justin Gilmer and
                  Samuel S. Schoenholz and
                  Patrick F. Riley and
                  Oriol Vinyals and
                  George E. Dahl},
  title        = {Neural Message Passing for Quantum Chemistry},
  journal      = {CoRR},
  volume       = {abs/1704.01212},
  year         = {2017},
  url          = {http://arxiv.org/abs/1704.01212},
  eprinttype    = {arXiv},
  eprint       = {1704.01212},
  timestamp    = {Mon, 13 Aug 2018 16:48:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/GilmerSRVD17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%%% paper that introduced GraphBLAS
@article{DBLP:journals/corr/KepnerABBFGHKLM16,
  author       = {Jeremy Kepner and
                  Peter Aaltonen and
                  David A. Bader and
                  Aydin Bulu{\c{c}} and
                  Franz Franchetti and
                  John R. Gilbert and
                  Dylan Hutchison and
                  Manoj Kumar and
                  Andrew Lumsdaine and
                  Henning Meyerhenke and
                  Scott McMillan and
                  Jos{\'{e}} E. Moreira and
                  John D. Owens and
                  Carl Yang and
                  Marcin Zalewski and
                  Timothy G. Mattson},
  title        = {Mathematical Foundations of the GraphBLAS},
  journal      = {CoRR},
  volume       = {abs/1606.05790},
  year         = {2016},
  url          = {http://arxiv.org/abs/1606.05790},
  eprinttype    = {arXiv},
  eprint       = {1606.05790},
  timestamp    = {Tue, 21 Jan 2020 16:22:06 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/KepnerABBFGHKLM16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%% paper that talsk about GNN and machine learning trends, to cite when talking about the increasing interest in GNN
%% in Graph Neural Networks background - Chapter 2
@article{KERAMATFAR2022100401,
title = {Graph Neural Networks: A bibliometrics overview},
journal = {Machine Learning with Applications},
volume = {10},
pages = {100401},
year = {2022},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2022.100401},
url = {https://www.sciencedirect.com/science/article/pii/S2666827022000780},
author = {Abdalsamad Keramatfar and Mohadeseh Rafiee and Hossein Amirkhani},
keywords = {Bibliometrics, Graph Convolutional Network, Graph Neural Network, Graph representation learning},
abstract = {Recently, graph neural networks (GNNs) have become a hot topic in machine learning community. This paper presents a Scopus-based bibliometric overview of the GNNsâ research since 2004 when GNN papers were first published. The study aims to evaluate GNN research trends, both quantitatively and qualitatively. We provide the trend of research, distribution of subjects, active and influential authors and institutions, sources of publications, most cited documents, and hot topics. Our investigations reveal that the most frequent subject categories in this field are computer science, engineering, and telecommunications. In addition, the most active source of GNN publications is Lecture Notes in Computer Science. The most prolific or impactful institutions are found in the United States, China, and Canada. We also provide must-read papers based on citation count and future directions. Our analysis reveals that node classification is the most popular task, followed by link prediction, and graph classification in the GNN literature. Moreover, the results suggest that the application of graph convolutional networks and attention mechanisms are now among hot topics of GNN research. Finally, scalability, generalization, over-smoothing, and explainability of graph neural networks are some research directions to pursue.}
}

%% cuBLAS main page
@online{cublas,
    author = {NVIDIA},
    title = {cuBLAS Library},
    date = {23-July-2023},
    url = {https://developer.nvidia.com/cublas},
}

%% openBLAS main page
@online{openblas,
    author = {Zhang Xianyi and other contributors},
    title = {OpenBLAS Library},
    date = {23-July-2023},
    url = {http://www.openblas.net},
}

%% paper that introduced GCoD
@INPROCEEDINGS{9773223,
  author={You, Haoran and Geng, Tong and Zhang, Yongan and Li, Ang and Lin, Yingyan},
  booktitle={2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  title={GCoD: Graph Convolutional Network Acceleration via Dedicated Algorithm and Accelerator Co-Design},
  year={2022},
  volume={},
  number={},
  pages={460-474},
  doi={10.1109/HPCA53966.2022.00041}}

%% paper that talsk about geometric deep learning, going beoyond euclidean data
@article{DBLP:journals/corr/BronsteinBLSV16,
  author       = {Michael M. Bronstein and
                  Joan Bruna and
                  Yann LeCun and
                  Arthur Szlam and
                  Pierre Vandergheynst},
  title        = {Geometric deep learning: going beyond Euclidean data},
  journal      = {CoRR},
  volume       = {abs/1611.08097},
  year         = {2016},
  url          = {http://arxiv.org/abs/1611.08097},
  eprinttype    = {arXiv},
  eprint       = {1611.08097},
  timestamp    = {Mon, 13 Aug 2018 16:48:20 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/BronsteinBLSV16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%% paper that explain the WL test
@article{weisfeiler1968reduction,
  title={The reduction of a graph to canonical form and the algebra which appears therein},
  author={Weisfeiler, Boris and Leman, Andrei},
  journal={nti, Series},
  volume={2},
  number={9},
  pages={12--16},
  year={1968}
}

$$ introduction to HLS
@ARTICLE{5209958,
  author={Coussy, Philippe and Gajski, Daniel D. and Meredith, Michael and Takach, Andres},
  journal={IEEE Design \& Test of Computers},
  title={An Introduction to High-Level Synthesis},
  year={2009},
  volume={26},
  number={4},
  pages={8-17},
  doi={10.1109/MDT.2009.69}}

%% torchscript docs page
@online{torchscript,
    author = {PyTorch Team},
    title = {TorchScript Docs},
    year = {2019},
    date = {03-Aug-2023},
    url = {https://pytorch.org/docs/stable/jit.html},
}

%% mlir-pytaco presentation
@online{mlir-pytaco,
    author = {Bixia Zheng, Aart Bik, and other Torch-MLIR contributors},
    title = {MLIR-PyTACO: An End-to-End Use Case For the Sparse Tensor Compiler},
    year = {2022},
    date = {07-Aug-2023},
    url = {https://mlir.llvm.org/OpenMeetings/2022-02-10-PyTACO.pdf},
}

%% taco official website
@online{taco,
    author = {Members of Prof. Fredrik Kjolstad's research group at Stanford University, members of the COMMIT research group (led by Prof. Saman Amarasinghe) at MIT CSAIL, and other contributors},
    title = {TACO: The Tensor Algebra Compiler},
    year = {2016},
    date = {08-Aug-2023},
    url = {http://tensor-compiler.org},
}

% aten namespace documentation
@online{aten,
    author = {PyTorch Team},
    title = {ATen: a Tensor library},
    year = {2019},
    date = {07-Sept-2023},
    url = {https://pytorch.org/cppdocs/api/namespace_at.html#namespace-at},
}