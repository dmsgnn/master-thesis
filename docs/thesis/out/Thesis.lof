\babel@toc {english}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of directed and undirected graphs\relax }}{5}{figure.caption.9}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Directed Graph}}}{5}{subfigure.1.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Undirected Graph}}}{5}{subfigure.1.2}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a graph and its adjacency matrix\relax }}{6}{figure.caption.10}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Graph}}}{6}{subfigure.2.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Adjacency matrix}}}{6}{subfigure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces COO and CSR format of Adjacency matrix in Figure~\ref {fig:graph_adjacency}\relax }}{7}{figure.caption.11}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {COO format}}}{7}{subfigure.3.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {CSR format}}}{7}{subfigure.3.2}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Number of GNN publications on Google Scholar per year}}{9}{figure.caption.12}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Example of a Multi-Layer Perceptron\relax }}{11}{figure.caption.13}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces High-level Synthesis design steps~\cite {5209958}\relax }}{14}{figure.caption.17}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Overall architecture of SpMM engine in AWB-GCN~\cite {DBLP:journals/corr/abs-1908-10834}}}{21}{figure.caption.19}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces EnGN hardware architecture~\cite {DBLP:journals/corr/abs-1909-00155}\relax }}{23}{figure.caption.20}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Block diagram of a tile in the GNN accelerator proposed by Auten \textit {et al.}~\cite {9218751}\relax }}{24}{figure.caption.21}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Architecture overview of HyGCN~\cite {DBLP:journals/corr/abs-2001-02514}\relax }}{25}{figure.caption.22}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces High-level overview of GRIP~\cite {DBLP:journals/corr/abs-2007-13828}\relax }}{27}{figure.caption.23}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Baseline dataflow architecture and the improved FlowGNN architecture~\cite {sarkar2022flowgnn}\relax }}{30}{figure.caption.24}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Hardware architecture with two execution modes proposed by Zhang \textit {et al.}~\cite {9153263}\relax }}{33}{figure.caption.25}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces BoostGCN framework overview~\cite {9444065}\relax }}{34}{figure.caption.26}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces FPGA Toolchain for Graph Neural Network Acceleration\relax }}{44}{figure.caption.29}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Torch-MLIR flow\relax }}{46}{figure.caption.32}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Synthesizer: SODA-OPT and PandA-Bambu overview~\cite {9786533}\relax }}{51}{figure.caption.33}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Compiler frontend}}}{51}{subfigure.3.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {High-level synthesis backend}}}{51}{subfigure.3.2}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Row-by-column matrix multiplication example\relax }}{56}{figure.caption.39}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Matrix multiplication memory coalescing~\cite {opt_cuda_matmul}\relax }}{57}{figure.caption.40}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Performance comparison between PyTorch matmul function and accelerator\relax }}{63}{figure.caption.45}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Matrix multiplication optimization comparison\relax }}{64}{figure.caption.46}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Input matrices $15\times 15$, $15\times 16$}}}{64}{subfigure.2.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Input matrices $30\times 30$, $30\times 16$}}}{64}{subfigure.2.2}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces GCN inference PyTorch-Accelerator comparison\relax }}{66}{figure.caption.49}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces GCN inference number of cycles comparison\relax }}{68}{figure.caption.51}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Future FPGA Toolchain for Graph Neural Network Acceleration\relax }}{72}{figure.caption.54}%
