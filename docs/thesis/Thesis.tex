% MSc Thesis of Giovanni Demasi - 987062
% Politecnico di Milano (PoliMi) - School of Industrial and Information Engineering

\documentclass{Configuration_Files/PoliMi3i_thesis}

%------------------------------------------------------------------------------
%	REQUIRED PACKAGES AND  CONFIGURATIONS
%------------------------------------------------------------------------------

% CONFIGURATIONS
\usepackage{parskip} % For paragraph layout
\usepackage{setspace} % For using single or double spacing
\usepackage{emptypage} % To insert empty pages
\usepackage{multicol} % To write in multiple columns (executive summary)
\setlength\columnsep{15pt} % Column separation in executive summary
\setlength\parindent{0pt} % Indentation
\raggedbottom

% PACKAGES FOR TITLES
\usepackage{titlesec}
% \titlespacing{\section}{left spacing}{before spacing}{after spacing}
\titlespacing{\section}{0pt}{3.3ex}{2ex}
\titlespacing{\subsection}{0pt}{3.3ex}{1.65ex}
\titlespacing{\subsubsection}{0pt}{3.3ex}{1ex}
\usepackage{color}

% PACKAGES FOR LANGUAGE AND FONT
\usepackage[english]{babel} % The document is in English  
\usepackage[utf8]{inputenc} % UTF8 encoding
\usepackage[T1]{fontenc} % Font encoding
\usepackage[11pt]{moresize} % Big fonts

% PACKAGES FOR IMAGES
\usepackage{graphicx}
\usepackage{transparent} % Enables transparent images
\usepackage{eso-pic} % For the background picture on the title page
\usepackage{subfig} % Numbered and caption subfigures using \subfloat.
\usepackage{tikz} % A package for high-quality hand-made figures.
\usetikzlibrary{}
\graphicspath{{./Images/}} % Directory of the images
\usepackage{caption} % Coloured captions
\usepackage{xcolor} % Coloured captions
\usepackage{amsthm,thmtools,xcolor} % Coloured "Theorem"
\usepackage{float}

% STANDARD MATH PACKAGES
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage[overload]{empheq} % For braced-style systems of equations.
\usepackage{fix-cm} % To override original LaTeX restrictions on sizes

% PACKAGES FOR TABLES
\usepackage{tabularx}
\usepackage{longtable} % Tables that can span several pages
\usepackage{colortbl}

% PACKAGES FOR ALGORITHMS (PSEUDO-CODE)
\usepackage{algorithm}
\usepackage{algorithmic}

% PACKAGES FOR REFERENCES & BIBLIOGRAPHY
\usepackage[colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,filecolor=black,menucolor=black,runcolor=black,urlcolor=black]{hyperref} % Adds clickable links at references
\usepackage{cleveref}
\usepackage[square, numbers, sort&compress]{natbib} % Square brackets, citing references with numbers, citations sorted by appearance in the text and compressed
\bibliographystyle{abbrvnat} % I may use a different style adapted to your field

% OTHER PACKAGES
\usepackage{pdfpages} % To include a pdf file
\usepackage{afterpage}
\usepackage{lipsum} % DUMMY PACKAGE
\usepackage{fancyhdr} % For the headers
\fancyhf{}

% Input of configuration file.
\input{Configuration_Files/config}

%----------------------------------------------------------------------------
%	NEW COMMANDS DEFINED
%----------------------------------------------------------------------------

%----------------------------------------------------------------------------
%	ADDITIONAL PACKAGES
%----------------------------------------------------------------------------

%----------------------------------------------------------------------------
%	ADDITIONAL DEFINITIONS AND COMMANDS
%----------------------------------------------------------------------------

%----------------------------------------------------------------------------
%	DOCUMENT
%----------------------------------------------------------------------------

\begin{document}
    \nocite{*}

    \fancypagestyle{plain}{%
        \fancyhf{} % Clear all header and footer fields
        \fancyhead[RO,RE]{\thepage} %RO=right odd, RE=right even
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}}

%----------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------

    \pagestyle{empty} % No page numbers
    \frontmatter % Use roman page numbering style (i, ii, iii, iv...) for the preamble pages

    \puttitle{
        title=Graph Neural Network \\ Acceleration with SODA \\ Framework, % Title of the thesis
        name=Giovanni Demasi, % Author Name and Surname
        course=Computer Science and Engineering, % Study Programme
        ID  = 987062,  % Student ID number (numero di matricola)
        advisor= Prof. Fabrizio Ferrandi, % Supervisor name
        coadvisor={Serena Curzel}, % Co-Supervisor name
        academicyear={2022-23},  % Academic Year
    } % These info will be put into your Title page

%----------------------------------------------------------------------------
%	PREAMBLE PAGES: ABSTRACT (inglese e italiano), EXECUTIVE SUMMARY
%----------------------------------------------------------------------------
    \startpreamble
    \setcounter{page}{1} % Set page counter to 1

% ABSTRACT IN ENGLISH
    \chapter*{Abstract}
    Here goes the Abstract in English of your thesis followed by a list of keywords.
    The Abstract is a concise summary of the content of the thesis (single page of text)
    and a guide to the most important contributions included in your thesis.
    The Abstract is the very last thing you write.
    It should be a self-contained text and should be clear to someone who hasn't (yet) read the whole manuscript.
    The Abstract should contain the answers to the main scientific questions that have been addressed in your thesis.
    It needs to summarize the adopted motivations and the adopted methodological approach as well as the findings of your work and their relevance and impact.
    The Abstract is the part appearing in the record of your thesis inside POLITesi,
    the Digital Archive of PhD and Master Theses (Laurea Magistrale) of Politecnico di Milano.
    The Abstract will be followed by a list of four to six keywords.
    Keywords are a tool to help indexers and search engines to find relevant documents.
    To be relevant and effective, keywords must be chosen carefully.
    They should represent the content of your work and be specific to your field or sub-field.
    Keywords may be a single word or two to four words.
    \\
    \\
    \textbf{Keywords:} here, the keywords, of your thesis % Keywords

% ABSTRACT IN ITALIAN
    \chapter*{Abstract in Lingua Italiana}
    Qui va l'Abstract in lingua italiana della tesi seguito dalla lista di parole chiave.
    \\
    \\
    \textbf{Parole chiave:} qui, vanno, le parole chiave, della tesi % Keywords (italian)

%----------------------------------------------------------------------------
%	LIST OF CONTENTS/FIGURES/TABLES/SYMBOLS
%----------------------------------------------------------------------------

% TABLE OF CONTENTS
    \thispagestyle{empty}
    \tableofcontents % Table of contents
    \thispagestyle{empty}
    \cleardoublepage

%-------------------------------------------------------------------------
%	THESIS MAIN TEXT
%-------------------------------------------------------------------------
% In the main text of this thesis it is possible to write the chapters in two different ways:
%
%(1) It is possible to write:
%    \chapter{Title of the chapter}
%    *body of the chapter*
%
%(2) It is also possible to write the chapter in a separated .tex file and then include it in the main file with the following command:
%    \chapter{Title of the chapter}
%    \input{chapter_file.tex}
%
% Especially for long thesis, the second option is the recommended one.

    \addtocontents{toc}{\vspace{2em}} % Add a gap in the Contents, for aesthetics
    \mainmatter % Begin numeric (1,2,3...) page numbering

% ##########################################################################
% CHAPTER ONE - INTRODUCTION
% ##########################################################################

    \chapter{Introduction}
    \label{ch:chapter_one}%

    In recent years, deep learning has brought about a revolutionary transformation in various machine learning tasks,
    spanning from image classification and video processing to speech recognition and natural language understanding.
    Traditionally, these tasks have predominantly operated within the Euclidean space, where data is typically
    represented.
    Nevertheless, a growing number of applications now generate data from non-Euclidean domains,
    presenting it in the form of complex graphs with intricate relationships and interdependencies among objects.
    The inherent complexity of graph data has posed considerable challenges for existing machine learning algorithms.
    Consequently, there has been a surge of studies focusing on extending deep learning techniques to accommodate
    and leverage graph data.

    Graph neural networks (GNNs) have been introduced in response to the growing demand for learning tasks involving
    graph data, which encompasses extensive relational information among its elements.
    These neural models effectively capture the interdependence among graph nodes by employing message passing mechanisms.

    As Graph Neural Networks are increasingly employed, particularly in domains characterized by vast amounts of data,
    such as social networks and chemistry, a need arises to optimize and accelerate their capabilities.
    Inference in GNNs refers to the time the model takes to make predictions after training.
    The duration of the inference process determines the speed at which queries are answered, and researchers strive to minimize this time span.

    In applications of deep learning that prioritize low latency, FPGAs outperform other computing devices, such as CPUs and GPUs,
    by providing superior performance.
    FPGAs offer the advantage of being fine-tuned to strike the optimal balance between power efficiency and meeting performance requirements.

    Due to this reason, researchers have been actively pursuing the development of new FPGA accelerators for Graph Neural Networks (GNNs) in recent times.

    The conventional approach to hardware design involves a combination of manual coding and automated processing.
    However, this method demands significant effort and relies heavily on the expertise of the designers, leading to varying quality of results.

    To address these challenges, the objective of this thesis research study is to develop a comprehensive toolchain that, starting from PyTorch~\cite{DBLP:journals/corr/abs-1912-01703},
    a cutting-edge high-level programming framework for creating neural network algorithms based on the Python programming language, enables the
    automatic generation of a Graph Neural Networks (GNNs) FPGA accelerator with minimal effort required.

    The suggested toolchain represents an enhancement of the SODA toolchain~\cite{9786533}.
    It operates by transforming the PyTorch model, provided as input, into a multi-level intermediate representation
    (MLIR)~\cite{9370308} utilizing Torch-MLIR~\cite{torch_mlir}, an MLIR based compiler toolkit for PyTorch programs.
    This MLIR representation is then passed to the SODA framework to conduct hardware/software partitioning of the algorithm
    specifications and architecture-independent optimizations.
    Following this, the framework generates a low-level IR (LLVM IR) specifically tailored for the hardware generation engine,
    PandA-Bambu~\cite{9586110}.

    In pursuit of the thesis goal, various optimizations were adopted throughout the process.
    Specifically, efforts were made to optimize specific computations in Graph Neural Networks during the experimental phase.
    As these networks often deal with massive graph sizes, the computation time and memory requirements are substantial.
    Consequently, a significant portion of the research focuses on optimizing the computation phase of Graph Neural Networks using
    tailored SODA optimizations, particularly matrix multiplication.

    Furthermore, limitations and challenges have been encountered along the way.
    Another objective of this thesis is to analyze these limitations, ensuring they are clearly understood thoroughly.
    This analysis aims to provide valuable insights for future research endeavors, enabling the development of solutions
    to overcome these limitations and further enhance the proposed toolchain.

    While the intended purpose of the toolchain is to be general, the experimental phase primarily focused on two specific
    types of Graph Neural Networks: Graph Isomorphism Networks (GIN)~\cite{xu2019powerful} and Graph Convolutional Networks (GCN)~\cite{DBLP:journals/corr/KipfW16}.
    These models were sourced from reliable GitHub implementations and were modified as necessary.

    The GCN model~\cite{pygcn}, designed for node classification task and written in pure PyTorch, held particular importance for the
    experimental phase as it served as the basis for the resulting accelerator.
    On the other hand, the GIN model~\cite{ogb_gnn_models}, designed for graph classification task and written in PyTorch Geometric~\cite{DBLP:journals/corr/abs-1903-02428},
    a library built upon PyTorch for easier development and training of Graph Neural Networks, did not progress through
    the final step of the proposed toolchain.
    This was due to some incompatibilities between PyTorch Geometric and Torch-MLIR, which are integral parts of this thesis research.
    
    \section{Contributions}


    \section{Thesis structure}

    Chapter~\ref{ch:chapter_one} introduces the context of the thesis, its objective, and its goals, including a general overview of the research's focus, contributions, and outcome.
    Chapter~\ref{ch:chapter_two} presents the background needed to understand the thesis's content deeply.
    In particular, it contains a summary of Graph Neural Networks, how they work, an explanation of the GNN types used in the experimental phase, and the type of tasks that they can perform, including some of their applications.
    Additionally, it presents the SODA framework, an important part of this thesis's proposed toolchain.
    Chapter~\ref{ch:chapter_three} instead contains an overview of the related works.
    Other Graph Neural Network acceleration frameworks will be analyzed, underlying their differences compared to the research study done for this thesis and some limitations.
    Chapter~\ref{ch:chapter_four} formulates the problem statement, summarizes the open issues of the research objective, and explains how the thesis goals can be helpful and their expected impact.
    Chapter~\ref{ch:chapter_five} is the core chapter of the thesis, it clearly explains how the problem has been faced and what technologies have been used.
    It contains a detailed description of the proposed toolchain and its working method.
    Chapter~\ref{ch:chapter_six} lists all the performed experiments, gives the necessary information to reproduce them and contains their outcomes and the issues and limitations encountered.
    Finally, Chapter~\ref{ch:conclusions} presents overall considerations of the study, both with the main achievements obtained and the most notable obstacles faced.
    Along with this, potential improvements for future studies are considered.



% ##########################################################################
% CHAPTER TWO - BACKGROUND
% ##########################################################################


    \chapter{Background}
    \label{ch:chapter_two}%
% The \label{...}% enables to remove the small indentation that is generated, always leave the % symbol.

    Chapter containing the background needed to understand the problem and its solution, mainly a summary
    of Graph Neural Networks and SODA toolchain.

    \section{Graph Neural Networks}

    \section{SODA Toolchain}


% ##########################################################################
% CHAPTER THREE - RELATED WORK
% ##########################################################################


    \chapter{Related Work}
    \label{ch:chapter_three}%

    Analysis of related works, explaining how other GNN accelerators have been built, and some
    limitations of their approach.

% ##########################################################################
% CHAPTER FOUR - PROBLEM FORMULATION
% ##########################################################################


    \chapter{Problem Formulation}
    \label{ch:chapter_four}%

    Problem formulated in a clear way, what we did and how, with open issues and thesis goals.

% ##########################################################################
% CHAPTER FIVE - TOOLCHAIN
% ##########################################################################


    \chapter{FPGA Toolchain for Graph Neural Network Acceleration}
    \label{ch:chapter_five}%

    Introduction of the way I faced the problem, with the motivation for the followed approach.
    Explanation of the toolchain in a clear way.

% ##########################################################################
% CHAPTER SIX - EXPERIMENTAL RESULTS
% ##########################################################################


    \chapter{Experimental Results}
    \label{ch:chapter_six}%

    Chapter dedicated to the outcome of the results, what I have obtained and what limitations have been encountered.
    Explaining the still open issues and research suggestions.



% ##########################################################################
% CHAPTER SEVEN - CONCLUSION
% ##########################################################################

    \chapter{Conclusions and Future Developments}
    \label{ch:conclusions}%
    Final chapter containing the main conclusions of my research
    and possible future developments.

%##########################################################################
%	BIBLIOGRAPHY
%##########################################################################

    \addtocontents{toc}{\vspace{2em}} % Add a gap in the Contents, for aesthetics
    \bibliography{Thesis_bibliography} % The references information are stored in the file named "Thesis_bibliography.bib"

%-------------------------------------------------------------------------
%	APPENDICES
%-------------------------------------------------------------------------

    \cleardoublepage
    \addtocontents{toc}{\vspace{2em}} % Add a gap in the Contents, for aesthetics
    \appendix

%
%    \chapter{Appendix A}
%    If you need to include an appendix to support the research in your thesis, you can place it at the end of the manuscript.
%    An appendix contains supplementary material (figures, tables, data, codes, mathematical proofs, surveys, \dots)
%    which supplement the main results contained in the previous chapters.
%
%
%    \chapter{Appendix B}
%    It may be necessary to include another appendix to better organize the presentation of supplementary material.

% LIST OF FIGURES
    \listoffigures

% LIST OF TABLES
    \listoftables

% LIST OF SYMBOLS
% Write out the List of Symbols in this page
    \chapter*{List of Symbols} % You have to include a chapter for your list of symbols (
    \begin{table}[H]
        \centering
        \begin{tabular}{lll}
            \textbf{Variable} & \textbf{Description} & \textbf{SI unit} \\\hline\\[-9px]
            $\bm{u}$        & solid displacement   & m \\[2px]
            $\bm{u}_f$        & fluid displacement   & m \\[2px]
        \end{tabular}
    \end{table}

% ACKNOWLEDGEMENTS
    \chapter*{Acknowledgements}
    Acknowledgements here...

    \cleardoublepage

\end{document}
