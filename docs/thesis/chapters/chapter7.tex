This thesis tackled the challenge of accelerating Graph Neural Network inference by leveraging High-Level Synthesis techniques targeting FPGAs.

In Chapter~\ref{ch:chapter_five}, the design of the proposed toolchain was introduced, which allows to obtain a GNN inference accelerator starting directly from PyTorch.
PyTorch stands as one of the foremost high-level frameworks for neural network implementation, extensively recognized and employed within the community, making the proposed toolchain suitable for different applications.

The results of this research significantly contribute to the field of GNN acceleration, introducing a new perspective about how it is possible to obtain hardware accelerators for GNNs even without having any hardware design knowledge.
The toolchain offers different possibilities, and provides various optimization passes that can be used in the synthesizer step to fine-tune the accelerator capabilities.

Within the spectrum of optimizations made available by this toolchain, this thesis primarily delved into two key techniques:: the loop unrolling technique of SODA-OPT and the parallel memory access of PandA-Bambu with an external memory of thirty-two channels.
These optimizations allowed to achieve encouraging and promising result in accelerating the inference of the GCN model analysed.
By studying and understanding the model bottlenecks, it is possible to achieve consistent improvements.

Furthermore, the applicability of this toolchain extends to the industry area, making it a readily accessible resource for companies looking to explore and capitalize on the domain of GNN acceleration.

An equally noteworthy contribution of this thesis lies in the innovation brought to SODA-OPT and PandA-Bambu.
This research represents the first work exploring the loop-unrolling technique in combination with the recent added feature of using more than two memory channels, providing consistent result and insights for future studies.

Lastly, this study has also made substantial contribution in enhancing Torch-MLIR.
A new feature, the support of the constant of Tuple type, have been added and different areas of improvement have been identified, where more work would be needed to implement functionalities for the complete support of PyTorch Geometric.
Before this research, no examples were available on how to use Torch-MLIR with Graph Neural Networks, and the compatibility of PyTorch Geometric and Torch-MLIR was still an unexplored area.

\section{Future developments}
\label{sec:future-dev}%

