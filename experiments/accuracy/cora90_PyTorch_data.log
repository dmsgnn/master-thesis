*************************************************************
*** Log data of trained GCN model for accuracy comparison ***
*************************************************************
>> Labels shape: 90
tensor([5, 3, 4, 4, 1, 1, 2, 5, 5, 2, 5, 6, 1, 0, 5, 5, 4, 5, 5, 5, 2, 4, 6, 1,
        4, 2, 5, 1, 5, 3, 0, 5, 0, 5, 4, 4, 5, 4, 6, 4, 2, 1, 6, 5, 0, 4, 5, 0,
        1, 0, 0, 1, 2, 6, 2, 6, 2, 4, 5, 5, 4, 0, 1, 4, 0, 6, 0, 1, 5, 0, 2, 1,
        5, 4, 1, 0, 1, 5, 2, 2, 5, 1, 4, 5, 1, 4, 3, 3, 2, 2])
>> Features shape: 90x90
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
>> Adjacency matrix shape: 90x90
tensor(indices=tensor([[ 0,  0,  0,  1,  2,  3,  4,  5,  6,  7,  8,  8,  8,  9,
                        10, 11, 12, 12, 13, 14, 14, 14, 14, 15, 15, 16, 17, 18,
                        19, 19, 20, 20, 21, 22, 23, 23, 24, 24, 25, 25, 26, 27,
                        27, 28, 29, 30, 31, 31, 32, 33, 34, 34, 34, 35, 35, 36,
                        37, 38, 39, 39, 39, 40, 41, 41, 42, 43, 44, 44, 45, 46,
                        47, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
                        60, 61, 62, 63, 64, 65, 66, 66, 66, 67, 68, 69, 69, 70,
                        71, 71, 72, 73, 74, 74, 74, 75, 76, 77, 78, 79, 80, 80,
                        81, 82, 82, 83, 84, 84, 84, 85, 86, 87, 87, 88, 88, 89],
                       [ 0,  8, 14,  1,  2,  3,  4,  5,  6,  7,  0,  8, 14,  9,
                        10, 11, 12, 84, 13,  0,  8, 14, 31, 15, 80, 16, 17, 18,
                        19, 74, 20, 25, 21, 22, 23, 41, 24, 39, 20, 25, 26, 27,
                        84, 28, 29, 30, 14, 31, 32, 33, 34, 35, 66, 34, 35, 36,
                        37, 38, 24, 39, 82, 40, 23, 41, 42, 43, 44, 88, 45, 46,
                        47, 87, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
                        60, 61, 62, 63, 64, 65, 34, 66, 69, 67, 68, 66, 69, 70,
                        71, 74, 72, 73, 19, 71, 74, 75, 76, 77, 78, 79, 15, 80,
                        81, 39, 82, 83, 12, 27, 84, 85, 86, 47, 87, 44, 88, 89]]),
       values=tensor([0.3333, 0.3333, 0.3333, 1.0000, 1.0000, 1.0000, 1.0000,
                      1.0000, 1.0000, 1.0000, 0.3333, 0.3333, 0.3333, 1.0000,
                      1.0000, 1.0000, 0.5000, 0.5000, 1.0000, 0.2500, 0.2500,
                      0.2500, 0.2500, 0.5000, 0.5000, 1.0000, 1.0000, 1.0000,
                      0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 1.0000, 0.5000,
                      0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.5000,
                      0.5000, 1.0000, 1.0000, 1.0000, 0.5000, 0.5000, 1.0000,
                      1.0000, 0.3333, 0.3333, 0.3333, 0.5000, 0.5000, 1.0000,
                      1.0000, 1.0000, 0.3333, 0.3333, 0.3333, 1.0000, 0.5000,
                      0.5000, 1.0000, 1.0000, 0.5000, 0.5000, 1.0000, 1.0000,
                      0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.3333,
                      0.3333, 0.3333, 1.0000, 1.0000, 0.5000, 0.5000, 1.0000,
                      0.5000, 0.5000, 1.0000, 1.0000, 0.3333, 0.3333, 0.3333,
                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.5000,
                      1.0000, 0.5000, 0.5000, 1.0000, 0.3333, 0.3333, 0.3333,
                      1.0000, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000]),
       size=(90, 90), nnz=126, layout=torch.sparse_coo) 
>> Output shape: 90x7
tensor([[-2.5836e+00, -2.3369e+00, -1.9134e+00, -4.0342e+00, -2.2543e+00,
         -9.2323e-01, -1.8300e+00],
        [-4.1952e+00, -4.3235e+00, -2.3940e+00, -2.4249e-01, -3.4092e+00,
         -3.2566e+00, -3.7233e+00],
        [-8.7939e+00, -6.6265e+00, -9.0115e+00, -1.0805e+01, -2.4620e-02,
         -4.3015e+00, -4.6937e+00],
        [-1.0765e+01, -2.9160e+00, -7.9224e+00, -8.7099e+00, -9.8361e-02,
         -3.4162e+00, -5.0925e+00],
        [-5.8391e+00, -5.9982e-02, -6.3877e+00, -7.6513e+00, -3.1589e+00,
         -5.5545e+00, -4.9898e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-7.6517e+00, -6.9707e+00, -3.7262e+00, -5.5645e+00, -2.4379e+00,
         -1.3509e-01, -4.6364e+00],
        [-2.5836e+00, -2.3369e+00, -1.9134e+00, -4.0342e+00, -2.2543e+00,
         -9.2323e-01, -1.8300e+00],
        [-3.0898e+00, -3.8536e+00, -2.6715e-01, -4.4933e+00, -4.3370e+00,
         -2.2148e+00, -3.3727e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-3.5685e+00, -3.4302e+00, -3.6693e+00, -5.7153e+00, -1.9768e+00,
         -2.3689e+00, -3.8781e-01],
        [-2.5392e+00, -2.1815e-01, -3.7325e+00, -6.2826e+00, -4.4210e+00,
         -2.9941e+00, -3.5348e+00],
        [-4.5581e-02, -3.8385e+00, -4.8297e+00, -1.0020e+01, -7.3476e+00,
         -7.3364e+00, -4.2902e+00],
        [-3.6632e+00, -3.1571e+00, -2.7078e+00, -4.6353e+00, -2.2012e+00,
         -4.3569e-01, -2.3236e+00],
        [-6.1602e+00, -6.4195e+00, -5.2893e+00, -7.4844e+00, -4.0365e+00,
         -4.3940e-02, -4.1363e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-7.2471e+00, -8.1127e+00, -6.0215e+00, -8.9479e+00, -5.2029e+00,
         -1.4266e-02, -5.2792e+00],
        [-5.9979e+00, -4.0631e+00, -5.2497e+00, -7.1615e+00, -3.9079e+00,
         -5.7491e-02, -4.5970e+00],
        [-3.5390e+00, -4.6399e+00, -2.2334e-01, -5.5572e+00, -5.3219e+00,
         -2.0373e+00, -3.8014e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-3.2251e+00, -1.8430e-01, -3.6264e+00, -5.8074e+00, -3.3936e+00,
         -3.8425e+00, -3.1253e+00],
        [-7.2212e+00, -5.1020e+00, -6.3054e+00, -6.7248e+00, -2.1539e-01,
         -1.9431e+00, -3.2021e+00],
        [-3.5390e+00, -4.6399e+00, -2.2334e-01, -5.5572e+00, -5.3219e+00,
         -2.0373e+00, -3.8014e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-3.7372e+00, -6.6754e-02, -4.9911e+00, -7.6680e+00, -4.8011e+00,
         -4.4183e+00, -4.3266e+00],
        [-3.8345e+00, -4.8631e+00, -2.4394e+00, -5.2897e+00, -2.6786e+00,
         -3.5631e-01, -2.2119e+00],
        [-4.0991e+00, -4.3566e+00, -2.9897e+00, -1.4425e-01, -3.9890e+00,
         -4.1615e+00, -3.8867e+00],
        [-2.9354e-02, -4.3793e+00, -5.5350e+00, -1.0145e+01, -6.0427e+00,
         -9.0914e+00, -4.6131e+00],
        [-6.4419e+00, -5.4049e+00, -4.8729e+00, -6.3216e+00, -2.6846e+00,
         -1.0923e-01, -3.9276e+00],
        [-5.6234e-02, -3.6386e+00, -4.6580e+00, -9.6197e+00, -6.7114e+00,
         -6.9204e+00, -4.0962e+00],
        [-6.6472e+00, -7.1647e+00, -5.5972e+00, -7.7868e+00, -3.9333e+00,
         -4.1858e-02, -4.1851e+00],
        [-6.3591e+00, -4.7400e+00, -6.4823e+00, -7.7340e+00, -1.1529e-01,
         -2.7062e+00, -3.5178e+00],
        [-7.5300e+00, -5.3046e+00, -6.7763e+00, -7.6620e+00, -1.4638e-01,
         -2.2467e+00, -3.7591e+00],
        [-6.7204e+00, -7.1410e+00, -5.4176e+00, -7.6447e+00, -3.7092e+00,
         -4.8535e-02, -4.1374e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-4.9363e+00, -3.5317e+00, -4.2118e+00, -5.2935e+00, -5.4348e-01,
         -1.3767e+00, -2.2019e+00],
        [-1.7405e+00, -3.5361e+00, -4.1468e-01, -6.9802e+00, -5.8329e+00,
         -2.5657e+00, -2.9159e+00],
        [-3.2251e+00, -1.8430e-01, -3.6264e+00, -5.8074e+00, -3.3936e+00,
         -3.8425e+00, -3.1253e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-5.4790e+00, -5.7543e+00, -3.6952e+00, -7.1859e+00, -4.6898e+00,
         -5.6759e-02, -4.3392e+00],
        [-1.5209e+00, -2.6808e+00, -7.3369e-01, -5.2618e+00, -4.3789e+00,
         -2.1606e+00, -2.3039e+00],
        [-7.0623e+00, -6.1028e+00, -6.5385e+00, -6.6734e+00, -4.0368e-01,
         -1.2054e+00, -3.6204e+00],
        [-6.7499e+00, -6.6272e+00, -5.5709e+00, -7.1009e+00, -2.8572e+00,
         -9.1252e-02, -3.7872e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.0649e-01, -2.5352e+00, -4.6032e+00, -8.9097e+00, -7.4229e+00,
         -7.8325e+00, -4.5453e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-8.6142e+00, -6.3776e+00, -8.3311e+00, -9.8683e+00, -4.7950e-02,
         -3.4925e+00, -4.2531e+00],
        [-6.4739e+00, -6.2711e+00, -5.8215e+00, -6.5220e+00, -8.5798e-01,
         -6.6287e-01, -2.9423e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-7.4490e+00, -6.1706e+00, -6.7964e+00, -7.6094e+00, -3.4064e-01,
         -1.4825e+00, -2.8587e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6665e+00,
         -1.7109e+00, -1.6683e+00],
        [-8.4443e+00, -6.9129e+00, -7.2056e+00, -8.0066e+00, -7.1210e-01,
         -7.2884e-01, -3.7038e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.7079e+01, -1.2627e+01, -1.5257e+01, -1.4576e+01, -1.9007e-02,
         -3.9892e+00, -8.0834e+00],
        [-2.2659e+00, -2.1457e+00, -4.3123e+00, -6.6426e+00, -4.7289e-01,
         -3.3560e+00, -2.2397e+00],
        [-3.2170e+00, -3.6330e+00, -2.8218e+00, -6.1683e+00, -4.0671e+00,
         -2.1340e-01, -3.0591e+00],
        [-4.9082e+00, -5.1313e+00, -3.5086e+00, -4.2867e+00, -2.8523e+00,
         -1.7182e-01, -3.1426e+00],
        [-9.6057e-01, -1.7873e+00, -4.0848e+00, -6.9338e+00, -1.1608e+00,
         -4.3458e+00, -2.2450e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-7.3202e+00, -5.2767e+00, -6.6398e+00, -8.6124e+00, -4.8248e+00,
         -1.8441e-02, -5.8146e+00],
        [-7.2471e+00, -8.1127e+00, -6.0215e+00, -8.9479e+00, -5.2029e+00,
         -1.4266e-02, -5.2792e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-6.7983e+00, -4.7241e+00, -6.0960e+00, -8.0425e+00, -4.4283e+00,
         -2.9848e-02, -5.3175e+00],
        [-5.1621e-02, -3.6490e+00, -4.7914e+00, -9.8807e+00, -6.8525e+00,
         -7.0225e+00, -4.2692e+00],
        [-8.4157e+00, -7.3475e+00, -7.7145e+00, -1.0302e+01, -6.3389e+00,
         -3.9282e-03, -7.1200e+00],
        [-4.3206e+00, -4.1220e+00, -3.4683e+00, -4.8970e+00, -1.5130e+00,
         -5.8709e-01, -1.8601e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-6.1602e+00, -6.4195e+00, -5.2893e+00, -7.4844e+00, -4.0365e+00,
         -4.3940e-02, -4.1363e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6665e+00,
         -1.7109e+00, -1.6683e+00],
        [-3.4968e+00, -2.6236e+00, -2.8812e+00, -4.3477e+00, -1.0380e+00,
         -1.2249e+00, -1.7136e+00],
        [-6.4016e+00, -6.3023e+00, -5.5464e+00, -6.6802e+00, -1.2474e+00,
         -5.1013e-01, -2.2665e+00],
        [-3.0083e+00, -1.4038e-01, -4.1470e+00, -6.7445e+00, -4.4404e+00,
         -3.5300e+00, -3.7502e+00],
        [-7.8373e+00, -7.1662e+00, -6.6520e+00, -8.3638e+00, -3.1745e+00,
         -5.8818e-02, -4.3729e+00],
        [-9.6014e+00, -8.4407e+00, -8.1578e+00, -1.0471e+01, -5.4205e+00,
         -6.1191e-03, -6.8337e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00],
        [-1.5209e+00, -2.6808e+00, -7.3369e-01, -5.2618e+00, -4.3789e+00,
         -2.1606e+00, -2.3039e+00],
        [-1.8333e+00, -1.8580e+00, -1.4913e+00, -3.8977e+00, -2.6666e+00,
         -1.7109e+00, -1.6683e+00]], grad_fn=<LogSoftmaxBackward0>) 
Test set results:
Loss= 2.5330
Accuracy= 0.5556
