*************************************************************
*** Log data of trained GCN model for accuracy comparison ***
*************************************************************
>> Labels shape: 60
tensor([1, 4, 0, 0, 6, 6, 2, 1, 1, 2, 1, 5, 6, 3, 1, 1, 0, 1, 1, 1, 2, 0, 5, 6,
        0, 2, 1, 6, 1, 4, 3, 1, 3, 1, 0, 0, 1, 0, 5, 0, 2, 6, 5, 1, 3, 0, 1, 3,
        6, 3, 3, 6, 2, 5, 2, 5, 2, 0, 1, 1])
>> Features shape: 60x60
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
>> Adjacency matrix shape: 60x60
tensor(indices=tensor([[ 0,  0,  0,  1,  2,  3,  4,  5,  6,  7,  8,  8,  8,  9,
                        10, 11, 12, 13, 14, 14, 14, 14, 15, 16, 17, 18, 19, 20,
                        20, 21, 22, 23, 23, 24, 24, 25, 25, 26, 27, 28, 29, 30,
                        31, 31, 32, 33, 34, 34, 35, 35, 36, 37, 38, 39, 39, 40,
                        41, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
                        54, 55, 56, 57, 58, 59],
                       [ 0,  8, 14,  1,  2,  3,  4,  5,  6,  7,  0,  8, 14,  9,
                        10, 11, 12, 13,  0,  8, 14, 31, 15, 16, 17, 18, 19, 20,
                        25, 21, 22, 23, 41, 24, 39, 20, 25, 26, 27, 28, 29, 30,
                        14, 31, 32, 33, 34, 35, 34, 35, 36, 37, 38, 24, 39, 40,
                        23, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
                        54, 55, 56, 57, 58, 59]]),
       values=tensor([0.3333, 0.3333, 0.3333, 1.0000, 1.0000, 1.0000, 1.0000,
                      1.0000, 1.0000, 1.0000, 0.3333, 0.3333, 0.3333, 1.0000,
                      1.0000, 1.0000, 1.0000, 1.0000, 0.2500, 0.2500, 0.2500,
                      0.2500, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5000,
                      0.5000, 1.0000, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000,
                      0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
                      0.5000, 0.5000, 1.0000, 1.0000, 0.5000, 0.5000, 0.5000,
                      0.5000, 1.0000, 1.0000, 1.0000, 0.5000, 0.5000, 1.0000,
                      0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),
       size=(60, 60), nnz=76, layout=torch.sparse_coo) 
>> Output shape: 60x7
tensor([[ -2.2441,  -0.7432,  -1.9359,  -4.4836,  -3.0981,  -2.1206,  -2.3257],
        [ -4.1614,  -3.8769,  -2.6448,  -6.3342,  -0.1814,  -3.9182,  -3.2996],
        [ -0.0181,  -4.5901,  -9.1617,  -7.9743,  -7.6575,  -5.2762,  -6.3537],
        [ -0.0344,  -5.1191,  -8.4857,  -5.3280,  -7.1877,  -5.4453,  -4.0364],
        [ -5.9872,  -3.9685,  -4.7665,  -4.3231,  -5.5930,  -6.2047,  -0.0502],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -0.6480,  -0.8031,  -7.2320, -10.9675,  -7.4985,  -3.6120,  -7.3062],
        [ -2.2441,  -0.7432,  -1.9359,  -4.4836,  -3.0981,  -2.1206,  -2.3257],
        [ -4.2486,  -1.8245,  -0.8076,  -3.7365,  -1.8779,  -3.0517,  -1.8677],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -6.6315,  -4.3094,  -4.9913,  -4.4567,  -5.8224,  -6.6273,  -0.0382],
        [ -4.6560,  -6.0216,  -6.4217,  -0.0385,  -6.5145,  -6.2435,  -3.8745],
        [ -2.2184,  -0.4665,  -2.5228,  -5.2205,  -3.8684,  -2.2514,  -2.9524],
        [ -3.3295,  -0.0911,  -4.7347,  -8.4064,  -6.8771,  -3.3101,  -5.3601],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -0.8526,  -0.8343,  -4.5326,  -7.0324,  -5.0032,  -2.1842,  -4.7550],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -0.8526,  -0.8343,  -4.5326,  -7.0324,  -5.0032,  -2.1842,  -4.7550],
        [ -0.8526,  -0.8343,  -4.5326,  -7.0324,  -5.0032,  -2.1842,  -4.7550],
        [ -3.0500,  -3.0078,  -3.5696,  -2.6472,  -4.0855,  -4.1470,  -0.2593],
        [ -0.7919,  -0.8414,  -4.2733,  -6.8215,  -4.7538,  -2.5022,  -4.5719],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -0.8526,  -0.8343,  -4.5326,  -7.0324,  -5.0032,  -2.1842,  -4.7550],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -3.1011,  -0.1070,  -4.6558,  -7.9985,  -6.7741,  -3.2186,  -5.2126],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -4.8702,  -6.9400,  -7.1864,  -0.0341,  -6.9452,  -6.9008,  -3.8085],
        [ -2.4181,  -0.2161,  -3.8254,  -6.7964,  -5.4992,  -2.7335,  -4.3249],
        [ -5.0811,  -6.6826,  -7.2040,  -0.0226,  -7.4080,  -6.9282,  -4.3801],
        [ -3.0253,  -0.1071,  -4.9016,  -8.4857,  -6.9076,  -3.2163,  -5.4488],
        [ -0.0940,  -2.7664,  -7.2726,  -7.4824,  -6.7161,  -3.9061,  -5.4536],
        [ -0.0940,  -2.7664,  -7.2726,  -7.4824,  -6.7161,  -3.9061,  -5.4536],
        [ -3.1612,  -0.1005,  -4.7582,  -8.0939,  -6.9223,  -3.2452,  -5.4312],
        [ -0.8526,  -0.8343,  -4.5326,  -7.0324,  -5.0032,  -2.1842,  -4.7550],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -0.7919,  -0.8414,  -4.2733,  -6.8215,  -4.7538,  -2.5022,  -4.5719],
        [ -5.6235,  -0.0188,  -5.5133,  -9.6814,  -8.8900,  -4.7250,  -6.2571],
        [ -3.0500,  -3.0078,  -3.5696,  -2.6472,  -4.0855,  -4.1470,  -0.2593],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -3.6459,  -0.1589,  -3.1505,  -6.4478,  -5.3809,  -3.0594,  -3.6924],
        [ -5.6235,  -0.0188,  -5.5133,  -9.6814,  -8.8900,  -4.7250,  -6.2571],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -1.6148,  -0.8056,  -2.3857,  -4.8115,  -3.1959,  -1.9260,  -2.6968],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -4.1739,  -2.3371,  -2.6565,  -3.4729,  -3.6396,  -3.9185,  -0.3002],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -2.3733,  -1.0714,  -1.5748,  -3.9992,  -2.5921,  -2.1240,  -1.9344],
        [ -0.8526,  -0.8343,  -4.5326,  -7.0324,  -5.0032,  -2.1842,  -4.7550],
        [ -0.8526,  -0.8343,  -4.5326,  -7.0324,  -5.0032,  -2.1842,  -4.7550]],
       grad_fn=<LogSoftmaxBackward0>) 
Test set results:
Loss= 2.0296
Accuracy= 0.1667
